============================================================
FULL-SCALE TRAINING EXPERIMENT
============================================================
Episodes: 100
Episode length: 10
Unique shapes: 50
Device: cpu
============================================================

Creating synthetic dataset...
  Created 50 shapes

Creating model...
  Model parameters: 1,604,658
  Value function parameters: 61,825

Creating trainer...
  Trainer created (F/G frozen)

Starting training...
------------------------------------------------------------
Episode 10/100
  R_intrinsic: 0.0178
  Value (start): 0.1679
  TD loss: 0.0026
  Coherence: 0.4470
  Valence: 0.5821
Episode 20/100
  R_intrinsic: 0.0237
  Value (start): 0.2100
  TD loss: 0.0022
  Coherence: 0.4212
  Valence: 0.5865
Episode 30/100
  R_intrinsic: 0.0260
  Value (start): 0.2395
  TD loss: 0.0019
  Coherence: 0.4298
  Valence: 0.5917
Episode 40/100
  R_intrinsic: 0.0334
  Value (start): 0.1781
  TD loss: 0.0041
  Coherence: 0.4364
  Valence: 0.5979
Episode 50/100
  R_intrinsic: 0.0442
  Value (start): 0.4319
  TD loss: 0.0047
  Coherence: 0.4289
  Valence: 0.6051
Episode 60/100
  R_intrinsic: 0.0589
  Value (start): 0.5256
  TD loss: 0.0093
  Coherence: 0.4366
  Valence: 0.6134
Episode 70/100
  R_intrinsic: 0.0909
  Value (start): 0.7116
  TD loss: 0.0348
  Coherence: 0.4356
  Valence: 0.6229
Episode 80/100
  R_intrinsic: 0.1464
  Value (start): 1.3391
  TD loss: 0.0507
  Coherence: 0.4211
  Valence: 0.6339
Episode 90/100
  R_intrinsic: 0.2116
  Value (start): 2.5240
  TD loss: 0.1637
  Coherence: 0.4283
  Valence: 0.6464
Episode 100/100
  R_intrinsic: 0.3400
  Value (start): 4.9440
  TD loss: 1.6617
  Coherence: 0.4370
  Valence: 0.6614
------------------------------------------------------------
Training complete!

Saving results...
Metrics saved to results/full_scale_training/metrics.json
Intrinsic rewards plot saved to results/full_scale_training/intrinsic_rewards.png
Value function plot saved to results/full_scale_training/value_function.png
Agent state plot saved to results/full_scale_training/agent_state.png
============================================================
FULL-SCALE TRAINING EXPERIMENT REPORT
============================================================

Summary Statistics:
------------------------------------------------------------
  Total Episodes: 100.0000
  Final Intrinsic Reward: 0.3400
  Final Value (Start): 4.9440
  Final TD Loss: 1.6617
  Final Coherence: 0.4370
  Final Valence: 0.6614

Trends:
------------------------------------------------------------
  r_intrinsic: 0.0171 → 0.2895 (Δ +0.2724)
  value_start: 0.1675 → 3.2572 (Δ +3.0898)
  avg_coherence: 0.4328 → 0.4325 (Δ -0.0003)
  avg_valence: 0.5802 → 0.6546 (Δ +0.0744)

============================================================

Report saved to results/full_scale_training/report.txt

Model saved to results/full_scale_training/model_final.pt

============================================================
EXPERIMENT COMPLETE
============================================================
