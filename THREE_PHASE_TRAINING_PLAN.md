# 三相訓練計画：2/13実験の完全再現に向けて

**日付**: 2026年2月17日  
**著者**: Manus AI

## 1. 背景：三相訓練の必要性

これまでの実験で、以下の2つの重要な知見が得られた。

1. **エピソードリセットの重要性**：エピソードベースの訓練構造（「睡眠」）が、η爆発を防ぎ、随伴構造の安定性を確保する。
2. **F/G事前訓練の重要性**：ランダム初期化されたF/G（「見えない目」）では、Agent Cは内発的報酬を得られず、学習が進まない。

これらの知見に基づき、2/13実験を完全に再現するため、以下の三相訓練を順に実行する。

## 2. 三相訓練の全体像

| フェーズ | 目的 | 訓練対象 | 凍結対象 | 期待される成果 |
| :--- | :--- | :--- | :--- | :--- |
| **Phase 1** | **基本的な随伴訓練** | F, G | Agent C | F/Gが基本的な再構成能力を獲得（「見える目」） |
| **Phase 2** | **Slack保存訓練** | F, G | Agent C | F/GがSlackを保存する能力を獲得（「動く手」） |
| **Phase 3** | **内発的報酬ベースライン** | Agent C | F, G | Agent Cが内発的報酬を最大化するように学習 |

## 3. Phase 1: 基本的な随伴訓練

### 3.1 目的

Functor FとFunctor Gに、基本的な再構成能力（`points -> affordances -> points`）を学習させる。

### 3.2 訓練方法

- **損失関数**: Chamfer距離による再構成誤差
- **訓練対象**: F, G
- **凍結対象**: Agent C
- **データセット**: `SyntheticAffordanceDataset`
- **エポック数**: 50（2/13実験のログを参考に設定）

### 3.3 期待される成果

- 再構成誤差が十分に減少する
- F/Gが「見える目」として機能するようになる
- 訓練済みのF/Gをチェックポイントとして保存

## 4. Phase 2: Slack保存訓練

### 4.1 目的

F/Gに、Affordance Lossを通じて、Slack（ηとε）を保存する能力を学習させる。

### 4.2 訓練方法

- **損失関数**: 再構成誤差 + Affordance Loss
- **訓練対象**: F, G
- **凍結対象**: Agent C
- **データセット**: `SyntheticAffordanceDataset`
- **エポック数**: 50（2/13実験のログを参考に設定）

### 4.3 期待される成果

- Affordance Lossが十分に減少する
- F/GがSlackを保存する「動く手」として機能するようになる
- 訓練済みのF/Gをチェックポイントとして保存

## 5. Phase 3: 内発的報酬ベースライン

### 5.1 目的

Phase 2で訓練済みのF/Gを固定し、Agent Cが内発的報酬を最大化するように学習させる。

### 5.2 訓練方法

- **訓練構造**: エピソードベース（100エピソード × 10ステップ）
- **訓練対象**: Agent C
- **凍結対象**: F, G（Phase 2のチェックポイントをロード）
- **報酬**: 内発的報酬（Curiosity, Competence, Novelty）

### 5.3 期待される成果

- **Coherence（η）が安定する**
- **R_intrinsicが+1900%成長する**
- **Valenceが0.58から0.66に成長する**
- 2/13実験の完全な再現

## 6. 実装方針

1. Phase 1, 2, 3の訓練スクリプトをそれぞれ作成する。
2. 各フェーズの終わりに、訓練済みのモデル（特にF/G）をチェックポイントとして保存する。
3. 次のフェーズでは、前のフェーズのチェックポイントをロードして訓練を継続する。

この計画に基づき、まずPhase 1の実装から開始する。
