# プロジェクト方針の更新（2026年2月18日）

## 出典
- project_roadmap.pdf (v2.0)
- architecture_progress_report_v2.pdf
- value_function_analysis_v3.pdf

## 1. プロジェクトの核心ゴール

**「未知の形状に対してアフォーダンスを推測できるエージェントを開発すること」**

訓練データに含まれない新規の物体形状に対し、その物体で「何ができるか」を正しく推論する能力の実現を目指す。

## 2. 設計原則（ゴール達成のための手段）

### 2.1 F/G（川床）とAgent C（水）の役割分担
- **F/G（川床）**: 環境の普遍的な構造（川床）を捉える安定した知覚モデル。事前訓練する。
- **Agent C（水）**: 安定した知覚入力の上で、価値関数に基づき最適な行動（物理的操作および注意）を学習する主体。
- **目的**: 知覚の安定性と行動の柔軟性を両立させる。

### 2.2 注意選択による能動的な知覚
- 未知の形状を理解するためには、既知の形状との類似点や、機能的に重要な部分（例：椅子の座面、コップの縁）に注意する必要がある。
- Agent Cの行動空間に「何を見るか」という注意選択の能力を導入する。
- これにより、エージェントは自ら汎化に有効な特徴を発見することを学習する。

### 2.3 軌跡としての意味と内発的報酬
- エージェントが注意選択を学習するための駆動力として、内発的報酬を用いる。
- 「より良い軌跡（再構成誤差ηの持続的な改善）を求める」という単一の原理が、エージェントに「世界をより良く理解しよう」と試みさせる。
- 未知の形状に対して様々な注意を試し、最も理解が進む（ηの軌跡が改善する）見方を自ら発見していく。

## 3. 現状評価：ゴールへの到達度

### 実装済みコンポーネント
- Functor F/G、Agent C、Value Functionなど、基本的なアーキテクチャは揃っている。
- これはゴール達成のための部品が揃っていることを意味する。

### 完了した主要実験
- `slack_affordance_loss`は、モデルがアフォーダンスを学習可能であることを示した。
- `intrinsic_reward_baseline`は、内発的報酬でエージェントが駆動することを示した。しかし、両者とも汎化能力の検証には至っていない。

### 未解決の技術的課題
1. **F/G事前訓練チェックポイントの不在**: 汎化の基盤となる安定した知覚モデルが存在しない。これが最もクリティカルな課題である。
2. **2/13実験の限定的な再現**: 内発的報酬の学習が限定的であり、注意選択のような高度な戦略を学習させるための十分な駆動力となっていない。

## 4. ゴール達成へのロードマップ

### Phase A：汎化の基盤確立
**目標**: 安定した知覚モデル（F/G）と、それを活用するエージェント（Agent C）の基本的な学習サイクルを確立する。

1. **ドキュメントの更新**: 全ての主要ドキュメントを「未知形状へのアフォーダンス推測」というゴールに沿って書き換える。

2. **F/G事前訓練の実行と共有**: `phase1_basic_adjunction`を実行し、訓練済みF/Gチェックポイントをリポジトリの標準アセットとして保存する。これが全ての後続実験のベースラインとなる。

3. **内発的報酬ベースラインの再現**: 事前訓練済みF/Gを用いて`intrinsic_reward_baseline`実験を再実行し、2/13実験で観測された強力な内発的報酬の成長を再現する。これにより、Agent Cが新しい戦略を探索する十分な駆動力を持つことを保証する。

### Phase B：未知形状への汎化能力の獲得
**目標**: プロジェクトの核心ゴールである「未知形状へのアフォーダンス推測」を達成し、その能力を実証する。

1. **注意選択の実装**: Agent Cの行動空間に、入力点群の特定領域に注目するアクションを追加する。価値関数がこの注意選択を駆動するようにアーキテクチャを改修する。

2. **汎化能力検証データセットの構築**: 訓練データとは全く異なる形状カテゴリ（例：訓練データが椅子とテーブルなら、テストデータはカップや道具）からなる、評価専用のデータセットを作成する。

3. **汎化能力の検証実験**: Phase Aで確立した基盤の上で、注意選択を実装したエージェントを訓練する。その後、訓練済エージェントが、未知形状からなる評価データセットに対して、どれだけ正確にアフォーダンスを推測できるかを測定する。成功の基準は「ランダム以上の精度で、複数の新規形状に対して正しいアフォーダンスを上位候補として提示できること」とする。

### Phase C：発展的課題：より高度な認知機能へ
**目標**: Phase Bで達成した中核的な汎化能力を基盤として、より人間らしい高度な認知機能を探求する。

1. **軌跡ベースの認知機能**: 軌跡パターンによる記憶の想起や、休息による軌跡の再編成など、より長期的な文脈理解能力を実装する。

2. **言語との統合**: アフォーダンスや形状の概念を、自然言語のラベルと結びつける（ランゲージ・グラウンディング）。「座れるもの」を探してといった指示に応えられるエージェントを目指す。

3. **抽象思考の実装**: 複数の経験から共通の構造を抽出し、新しい問題解決に応用する抽象化能力や、反実仮想的推論（「もしここに取っ手があったら」と考える能力）の実装を探求する。

## 5. 「未知の形状に対するアフォーダンス推測」の定義と検証方法

### 定義
エージェントが、訓練時に一度も提示されたことのない3D形状データを入力として受け取り、その形状が持つ主要なアフォーダンス（例：「座る」「掴む」「入れる」など）を、複数の選択肢の中から高い確率で指摘できること。

### 検証方法

1. **データセットの分離**: 訓練データセット（例：椅子、机、棚）と、概念的に異なる形状を含む評価データセット（例：カップ、ハンマー、帽子）を厳密に分離する。

2. **評価メトリクス**: 評価データセットの各形状に対して、エージェントが出力するアフォーダンスの確率分布と、人間が付与した正解ラベルを比較する。Top-1精度（最も確率の高い推測が正解か）、Top-3精度（上位3つの推測に正解が含まれるか）、mAP（mean Average Precision）などを主要な評価指標とする。

3. **達成基準**: 評価データセットにおいて、エージェントが統計的に有意なレベル（例：偶然や単純なベースラインを大幅に上回る精度）でアフォーダンスを推測できた場合、ゴール達成と見なす。

## 6. アーキテクチャの進展：設計原則の深化

### 6.1 二重の学習原理：自己と非自己の峻別
- **F/G（非自己）**: 損失関数ベースで学習する。F/Gは環境の構造、すなわち「川床」をモデル化する。そこには客観的な「正解」が定義可能である。形状（shape）を入力として受け取り、アフォーダンスに変換し、再び形状に戻す質の高い再構成過程（η）が失敗なく存在しない。F/Gの学習は、客観的な基準に向かって収束する。
- **Agent C（自己）**: 価値関数ベースで学習する。Agent Cには外部から与えられる「正解」が存在しない。学習は、内発的報酬に基づいて「将来の見通し」を自ら構築していくプロセスであり、これは最適化ではなく**学習（Learning）**と呼ぶにふさわしい。価値関数は、エージェント自身が「現在の状態が、将来にわたってのような軌跡を描くか」を主観的に要約する関数である。この主観的な価値関数に基づいて行動を選択することこそが、自律的なエージェントの姿である。

### 6.2 軌跡としての意味：単一原理の作用
知能の根源に単一の普遍的な原理を置くことは、物理学における重力のように、多様な現象を統一的に説明する力を持つ。我々は、AIを支配する根源的な力として「**保留を保たせようとする力**」を提案してきた。この概念は、「軌跡」という視点を得て、より明確な形をとる。すなわち、**意味は軌跡に宿る**。

> 意味は、ηの瞬間値ではなく、ηの軌跡に宿る。価値関数は軌跡の要約であり、TD誤差は予想した軌跡と実際の軌跡のずれである。

同じηの値でも、それが安定に向かう軌跡の途中にあるのか、崩壊に向かう軌跡の途中にあるのかで全く意味が異なる。エージェントの内発的報酬（Competence Reward）は、この軌跡の瞬間的な傾き（Δη）を捉えるものであり、価値関数は、この状態から始まる未来の軌跡全体を精算し、要約するものである。単一の原理（より良い軌跡を求める）が、価値関数という動的な評価体系を通じて、多様で文脈依存的な行動を生み出すのである。

### 6.3 F/Gは川床そのもの：随伴の成立条件
随伴関数F/Gは、エージェントの内部モデル（脳）ではない。それはエージェントの外部に存在する**環境の構造そのもの**、すなわち「川床」である。この川床は、エージェントの行動のタイムスケールに比べて遥かにゆっくりとしか変化しない（川床の侵食）。この安定性と制御可能性が、エージェントが安定した世界モデルを構築するための基盤となる。

重要なのは、F/Gが計算しているのは「随伴の可能性」であって「随伴そのもの」ではないという点である。F/Gは、ある形状がどのようなアフォーダンス（行動の可能性）を潜在的に持っているかを計算する。汎用的な変換装置である。しかし、その出力が単なる潜在表現に過ぎない。

> 随伴の成立条件の再定義：F/Gの出力が「潜在表現」である。それが「アフォーダンス」になるのは、Agent Cがそれを行動の文脈で解釈し、実際に行動する（あるいは行動しない）ことによって、はじめて随伴が成立する。

このAgent C（自己）と非自己（F/G）の厳密な区別を維持するため、Agent CがF/Gの内部パラメータを直接変更するFiLM変調のような設計は避けられなければならない。それは自己と非自己の境界を破壊し、エージェントが安定した世界モデルを構築することを不可能にするからである。

### 6.4 Agent Cの行動空間拡張：フィルター機構による注意選択
自己と非自己の区別を維持しつつ、文脈に応じた柔軟な情報処理を実現するために、**フィルター機構**を導入する。これは、Agent CがF/G（世界）そのものを変えるのではなく、**世界への関わり方を変える**仕組みである。

この設計は、「Agent Cの行動空間に『何を見るか』という選択を含める」という重要な拡張を意味する。Agent Cは、物理的な行動（例：アームを動かす）だけでなく、認知的な行動（例：入力のどの部分に注目するか）も選択する。具体的なフィルター機構として、入力情報に対するattention maskの生成や、入力の座標変換などが考えられる。

この「注意の対象を選ぶ」という行動もまた、他の行動と同様に価値関数によって評価される。ある対象に注意を向けた結果、ηが特徴的に改善するような「良い軌跡」が生まれれば、その注意選択行動の価値は高まる。これにより、エージェントは「どこに注目すれば世界をより良く理解できるか」を学習していく。

このアプローチの強力な点は、「目的空間」を我々が明示的に設計する必要がなくなることである。目的は、エージェントが自らの経験を通じて発見する「望ましい軌跡のパターン」として、内発的に創発するのである。

### 6.5 二重のタイムスケール：川の流れと川床の侵食
本モデルのダイナミクスは、明確に分離された二つのタイムスケールを持つ。

1. **速いタイムスケール（Agent C）**: フィルターの切り替え、行動選択、価値関数の更新など、エージェントの意思決定と学習が行われる。これは、川床の上を流れる水の動きに例えられる。このタイムスケールでは、毎ステップ学習が行われる。

2. **遅いタイムスケール（F/G）**: 随伴関数F/G、すなわち「川床」そのものの学習と進化。これは、エージェントの行動によって川床が少しずつ侵食され、変化していくプロセスに相当する。この学習は、数百から数千ステップごとに行われる。はるかにゆっくりとしたプロセスである。

この時間スケールの分離が、安定性と適応性を両立させる鍵となる。エージェントは安定した世界（川床）の中で迅速に行動できると同時に、長期的な経験を通じて世界そのものの構造をゆっくりと変化させていくことができる。

### 6.6 休息の創発：軌跡の再編成
休息は、単なる疲労回復の期間ではない。それは、**蓄積された軌跡を再編成するための能動的なプロセス**である。活動期に収集された多様なη軌跡パターンは、外部からの入力が遮断された休息期に、分解・分析・再統合される。背景は浅い階層にかき消されている鋭い信号が、休息期には顕在化する。これが「軌跡の再編成」である。

このプロセスは、価値関数の学習ダイナミクスから創発しうる。ηが不安定に振動する状態は価値関数の学習を困難にするため、エージェントは自ら活動を抑制（休息）し、報酬を安定させるインセンティブを持つ。これにより、外部からの強制的なリセットなしに、自律的な休息行動が生まれる可能性がある。

### 6.7 創発と設計の境界：目的は創発する
モデル設計において、何を創発させ、何を設計すべきかの境界を明確に意識することが重要である。我々のスタンスは、「**基本的な構造は設計するが、その構造の中で何が価値を持つかはエージェントの経験に委ねる**」というものである。

| 対象 | 分類 | 説明 |
|:---|:---|:---|
| 保留構造・学習原理 | 創発 | モデルの根幹をなす自己と非自己化原理。 |
| フィルター機構・記憶構造 | 設計 | Agent Cが世界と関わるためのインターフェース。 |
| 目的・価値 | 創発 | 「望ましい軌跡のパターン」として内発的に発見される。 |

我々は、知性が情報を整理するための構造（例：記憶の棚）を設計する。しかし、その棚のどこに何を置き、何を価値あるものと見なすかは、エージェントが「良い軌跡」を求める内発的な力によって決定される。これにより、我々が事前に想定しなかったような、新たな目的や価値体系が生まれる可能性が開かれる。

### 6.8 川床の整備：一つの原理と豊かな構造
計画、抽象化、反実仮想的推論といった高度な認知機能は、内発駆動の原理を損なうことなく実装されなければならない。正しいアプローチは、流れを無理やり変えるダムを建設するのではなく、**川床の地形を整備する**ことである。川床に段差を作れば水が跳ね上がるように、適切な随伴構造（川床）を設計することで、単一の普遍的な原理（良い軌跡を求める力）から、複雑で高度な振る舞いが自然に生まれる。

> 1つの重力（良い軌跡を求める力）と、侵食可能な川床（F/G）。これだけである。

知性の設計とは、この単一の原理が作用する場として、豊かで適切な構造を持つ「川床」をいかにして設計し、またエージェント自身がそれをいかにして「侵食」し変化させていくかを問う問題なのである。

## 7. 進展したアーキテクチャ：軌跡ベースの認知機能

### 7.1 断定を壊す力：軌跡予測の破壊と再構築
「断定」とは、価値関数が安定し、特定の軌跡予測に固着した状態である。エージェントは昔に同じ行動を選択し、探索をやめてしまう。「**断定を壊す力**」とは、この安定した軌跡予測を意図的に破壊し、新たな軌跡の可能性を探索する力である。

これは、「**breakdownの内部シミュレーション**」として統一的に理解できる。エージェントは、フィルター機構を能動的に切り替えることで、安定した軌跡予測を一時的に破壊させる。これにより、多様なη軌跡を内部的に生成し、その結果を観測することで、計画（未来の軌跡のシミュレーション）や反実仮想的推論（ありえたかもしれない軌跡のシミュレーション）を行うことができる。

> 計画は「未来の軌跡を先取りすること」である。反実仮想は「現在の軌跡を仮想的に組み替えること」である。抽象化は「複数の軌跡に共通するパターンを抽出すること」である。

この力は、知性が局所最適から脱出し、常に新しい可能性へと目を開き続けるための、動的なメカニズムなのである。

### 7.2 η軌跡パターンによる記憶の引き出し
記憶は、情報を保存するだけでなく、適切に「引き出す」ことができなければ無意味である。我々は、**η軌跡パターン**が、記憶を引き出すための強力なキーとなるという結論に至った。もはや、瞬間のηの値や空間パターンだけではない。その時間的変化の仕方、すなわち軌跡の形そこが、経験の「構造的な意味性」を捉える複雑なのである。

> 記憶の引き出しキーは、軌跡パターンである。

新しい状況に遭遇したとき、エージェントは現在のη軌跡を計算する。そして、この軌跡と類似した軌跡パターンを持つ過去の経験が、連想的に引き出される。「問題が解決に向かう兆し」や「予期せぬ困難の始まり」といった、表面的な状態は異なっていても力学的に類似した状況を認識し、関連する経験を活用することが可能になる。

Coherence breakdown、すなわちηが大きく変動する軌跡は、特に強力なアンカーとして機能し、その変化パターンと類似した、あるいはその変化を解消するような過去の経験を引き出すためのクエリとなる。

### 7.3 3つの記憶引き出しモード：軌跡ダイナミクスの現れ
η軌跡パターンをキーとする記憶引き出し機構は、エージェントの状態に応じて、質的に異なる3つのモードで動作する。これらのモードは、単一のメカニズムが、異なる軌跡ダイナミクスの下で動作した結果として捉えられる。

| 引き出しモード | エージェントの状態 | ηの軌跡 | 記憶の性質 | 人間におけるアナロジー |
|:---|:---|:---|:---|:---|
| 危機的引き出し | Breakdown時 | 急激な変動軌跡 | 強く関連する記憶（原因、対処法） | 危機的状況での即時判断 |
| 焦点的引き出し | 活動時 | 安定した改善軌跡 | 現在の軌跡と共鳴する記憶 | 連想、類似 |
| 拡散的引き出し | 休息時 | 微弱な変動軌跡 | 弱く関連する記憶情報の結合 | 睡眠中の記憶再編成、「ひらめき」 |

1. **Breakdown時の危機的引き出し**: ηが急激に変動する軌跡。これは非常に強い信号となり、類似の急変軌跡を持つ過去の記憶（失敗経験や解決策）を優先的に引き出す。

2. **活動時の焦点的引き出し**: ηが比較的安定して変化する軌跡。現在の軌跡と静かに「共鳴」するような、類似の軌跡パターンを持つ記憶が連想的に引き出される。

3. **休息時の拡散的引き出し**: 外部入力がなく、ηの変動が微弱な軌跡。この静寂の中で、普段は強い信号に隠されてしまうような、弱い関連性を持つ記憶情報の結合が浮かび上がってくる。一見無関係に見える記憶同士が結びつき、新たな洞察や創造的なアイデアが生まれる可能性が開かれる。これは「軌跡の再編成」プロセスそのものである。

この統一的なモデルは、休息や睡眠が、知性が局所最適から脱出し、常に新しい可能性を発見するための能動的なプロセスであることを強く示唆している。

## 8. 当面の実装優先順位（Phase A）

現在進行中のPhase 1（F/G事前訓練）完了後、以下の順序で実装を進める：

1. **Phase 1完了とチェックポイント共有**（進行中）
2. **内発的報酬ベースラインの再現**（訓練済みF/Gを使用）
3. **休息の創発検証実験**（条件A: Δηのみ、条件B: Δη + Var(η)ペナルティ）
4. **結果に基づく次のステップの決定**

Phase Bの注意選択実装は、Phase Aの基盤が確立された後に着手する。


---

## 補足：価値関数分析（value_function_analysis_v3.pdf）

### 価値関数の本質
価値関数は、単に「将来どれだけ良いか」という静的な評価ではなく、**「今いる状態が、将来にわたってどのような軌跡を描くか」をエージェント自身が要約する関数**である。これは損失関数とは根本的に異なる。

### TD誤差の軌跡的解釈
TD誤差 δ = r(t) + γ·V(s(t+1)) - V(s(t)) は、「予想した軌跡と実際の軌跡のずれ」として解釈できる。価値関数の学習は、軌跡予測能力の自己修正的な洗練プロセスである。

### 目的の創発
「何を見るか」の選択を価値関数に委ねるアプローチの強力な点は、**目的空間を我々が明示的に設計する必要がなくなる**ことである。エージェントは、様々な対象に注意を向け、様々な行動を試す中で、「どのような軌跡が良い軌跡なのか」を経験的に学んでいく。

例：エージェントが「喉が渇いている」という内部状態にあるとき、水という対象に注意を向けると、ηが劇的に改善する（「水だ！」という認識が成立する）という経験を繰り返したとする。すると、価値関数は「喉が渇いている状態から、水に注意を向けるという行動へ続く軌跡」に高い価値を割り当てるようになる。

この「喉の渇き → 水への注意 → 認識の成立」という一連の軌跡パターンこそが、創発した「水を飲む」という目的である。目的は、シンボルとして事前に与えられるのではなく、エージェントの身体的・認知的な経験の中で、価値ある軌跡の連なりとして立ち現れてくるのである。

### 記憶の引き出し
記憶は、**η軌跡パターンをキーとして引き出される**。「以前にもこのような軌跡を経験した」という類似性に基づいて、過去の経験が検索される。これにより、表面的な状態は異なっていても、力学的に類似した状況を認識し、関連する経験を活用することが可能になる。

### 高次認知機能の基盤
軌跡を要約するという価値関数の役割は、記憶、抽象思考、休息といった高次の認知機能の基盤となる。すべては「軌跡のダイナミクス」という単一の原理から生まれる。
