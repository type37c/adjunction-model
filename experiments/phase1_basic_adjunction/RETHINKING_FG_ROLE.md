# F/Gの役割とPhase 1の学習の妥当性に関する再考察

**文書バージョン**: 1.0  
**作成日**: 2026-02-18  
**作成者**: Manus AI

## 1. はじめに：提起された論点

前回の考察（`GENERALIZATION_ANALYSIS.md`）では、Phase 1で学習したF/G（Functor F/G）モデルの汎化能力の限界を指摘した。しかし、「**F/Gはただの単純な装置であるべきで、この最小の学習でも良いのではないか**」という重要な論点が提起された。

本ドキュメントは、この視点に基づき、プロジェクトの理論的枠組み（`THEORY.md`, `ARCHITECTURE.md`）に立ち返り、F/Gの真の役割とPhase 1の学習の妥当性を再考察するものである。

## 2. F/Gの役割の再定義：「川床」としての知覚基盤

理論文書、特に`ARCHITECTURE.md`で提示されている**「川床と水」**の比喩は、F/Gの役割を理解する上で核心的である。

-   **F/G (川床):** 環境の普遍的で客観的な構造を捉える。その学習は遅いタイムスケールで行われ、エージェントの意思決定の安定した基盤（川床）を提供する。
-   **Agent C (水):** 安定した川床の上を流れる水のように、内発的報酬に基づいて最適な行動を学習する主体。

この設計思想に立てば、F/Gに複雑な汎化能力や推論能力を求めるのは、役割の混同である。F/Gの役割は、**賢くなることではなく、Agent Cが賢くなるための安定した「座標系」を提供すること**にある。

> F/Gは世界を解釈する装置ではなく、世界をAgent Cが解釈可能な形式に**変換するだけの単純な装置**であるべきだ。知性や汎化能力の主役は、あくまでAgent Cである。

## 3. Phase 1の学習は「必要十分」である

この再定義された役割に照らすと、Phase 1の学習内容は、決して不十分ではなく、むしろ**「必要十分」**であったと結論付けられる。

| Phase 1の学習内容 | F/Gが獲得した能力（役割） |
| :--- | :--- |
| **形状の再構成** | Agent Cに対して、観測した形状が「どのようなものであるか」という安定した知覚情報を提供する能力。これは、Agent Cが行動結果を評価するための基準（η）を計算する上で不可欠。 |
| **アフォーダンスの予測** | 3種類の基本形状に対して、基本的なアフォーダンスの「辞書」を学習した状態。これは、Agent Cが行動を計画する際の最も基本的な語彙を提供する。 |

Phase 1は、F/Gに汎化能力を授けたわけではない。そうではなく、Agent Cがこれから汎化能力を獲得していくための、**最低限の、しかし不可欠な準備（プリミティブな知覚と語彙）**を整えた段階と評価すべきである。

## 4. 汎化能力はどこから創発するのか？

では、真の汎化能力はどこから生まれるのか。それは、F/Gという単純な装置を、Agent Cが**いかに使いこなすか**というプロセス全体から創発される。

1.  **能動的な注意選択 (Agent Cの役割):**
    `ARCHITECTURE.md`で構想されている通り、Agent CはF/Gへの入力に対してフィルター（Attention Maskなど）をかけることで、「どこに注目するか」を自ら選択する。未知のオブジェクト「取っ手のついた立方体」に遭遇したとき、Agent Cは「取っ手部分」と「立方体部分」に別々に注意を向け、それぞれの部分についてF/Gに問い合わせる。F/Gはそれぞれの部分が既知の形状（円柱や立方体）に類似していると報告するだけであり、それらを統合して「掴める」と推論するのはAgent Cの役割である。

2.  **内発的報酬による探索 (Agent Cの役割):**
    Agent Cは、自身の予測誤差（ηの変動）を内発的報酬として、未知の形状やインタラクションを試す。F/Gが提供する安定した座標系の上で、Agent Cは「こう動けばηがこう変わる」という関係性を学習し、自らの世界モデルを構築していく。この試行錯誤のプロセスこそが、教師なしでのアフォーダンス発見、すなわち汎化能力の源泉となる。

## 5. 結論：Phase 1は成功であり、次のステップへ

提起された論点に基づき再考察した結果、Phase 1の学習は、F/Gに課せられた「安定した知覚基盤を提供する」という役割を十分に満たしており、プロジェクトは正しい軌道上にあると結論付けられる。

F/Gをこれ以上賢くする必要はない。むしろ、この**単純で安定したF/G**を基盤として、**Agent Cを主役とした次のフェーズ（能動的注意選択と内発的報酬による探索）**に速やかに移行することが、真の汎化能力獲得への最も確実な道筋である。

今後の開発は、F/Gの改良ではなく、Agent CがF/Gをいかに能動的に「使いこなす」かの実装に焦点を当てるべきである。
