# Phase 1 学習モデルの汎化能力に関する考察

**文書バージョン**: 1.0  
**作成日**: 2026-02-18  
**作成者**: Manus AI

## 1. はじめに

本ドキュメントは、提供されたギャップ分析レポート (`phase1_gap_analysis.pdf`) と、完了したPhase 1実験の結果に基づき、現在のF/G（Functor F/G）学習モデルが**未知の形状に対してアフォーダンスを推測する能力（汎化能力）**をどの程度持つか、またその限界はどこにあるかを考察するものです。

## 2. Phase 1で達成されたことと、その限界

Phase 1の実験は、F/Gが基本的な形状（立方体、円柱、球）を正確に再構成し、それらに対応するアフォーダンスを予測できることを示しました。これは、エージェントが環境を安定して知覚するための**「見る」能力の基盤**が確立されたことを意味します。

しかし、この学習は本質的に**「記憶」と「分類」**に留まります。ギャップ分析レポートが指摘するように、未知の形状への対応という最終目標に対しては、根本的な課題が残されています。

| 達成事項 | 汎化における限界 |
|---|---|
| **形状の再構成**<br>訓練データに含まれる既知の形状を、アフォーダンス表現経由で正確に復元できる。 | **部分・組み合わせへの非対応**<br>形状全体を一つのパターンとして記憶しているため、「取っ手のついた立方体」のような未知の組み合わせや、形状の一部分だけを理解・推論することができない。 |
| **アフォーダンスの予測**<br>既知の形状に対して、教師ラベルとして与えられたアフォーダンスを正しく分類・予測できる。 | **「推測」能力の欠如**<br>学習は形状とアフォーダンスの決定論的なマッピング（1対1の対応付け）に過ぎない。平らな面が「積める」といった、形状の**幾何学的特徴**とアフォーダンスの**関係性**を学習していないため、未知の形状に対してアフォーダンスを「推測」または「創発」させるメカニズムが存在しない。 |
| **安定した知覚基盤**<br>後続のフェーズでAgent Cが利用できる、安定した特徴量（アフォーダンス表現）を生成できる。 | **受動的な情報処理**<br>F/Gは与えられた情報をただ処理するだけであり、アフォーダンスの推測に重要な部分へ「注目」したり、別の角度から「観察」したりといった、**能動的な情報収集**ができない。 |

## 3. なぜ未知の形状に対応できないのか？

現在のモデルが汎化能力を持たない理由は、主に以下の2点に集約されます。

### 3.1. 学習の対象が「全体形状」であり「構成要素」ではないため

現在のモデルは、「立方体という形状」と「掴める、積めるというラベル」を関連付けて記憶しています。しかし、「平らな上面があるから積める」「側面があるから掴める」といった、より根源的な**形状の構成要素（パーツ）や幾何学的特徴**とアフォーダンスの関係性を学習していません。

> これは、人間が「取っ手」というパーツを見れば、それが付いているのがカップであろうと箱であろうと「掴める」と推測できるのとは対照的です。モデルにはこの**構成性（Compositionality）**の理解が欠けています。

### 3.2. 学習プロセスが「教師あり学習」の枠組みに留まっているため

Phase 1は、形状とアフォーダンスの正解ペアを与える教師あり学習です。このアプローチは既知のパターンを効率的に学習できますが、**未知の状況で自ら答えを見つけ出す「推論」能力**は育ちません。

ギャップ分析レポートが指摘するように、真の汎化能力を獲得するには、エージェントが自らの「好奇心」に基づいて未知の形状やインタラクションを試し、その結果からアフォーダンスを発見していくプロセスが不可欠です。これは、単に正解を模倣するのではなく、**内発的な動機付けによって自律的に学習する**ことを意味します。

## 4. 汎化能力獲得に向けた次のステップ

ギャップ分析レポートで提示されている通り、これらの課題を解決し、未知の形状へ対応する「推測」能力を獲得するためには、以下のステップが不可欠です。

1.  **多様なデータセットの構築 (Roadmap B-2)**
    まずは、より複雑で多様な形状（例: 複数の基本形状の組み合わせ）を含むデータセットを構築し、モデルが構成的な特徴を学習する機会を提供します。これは、汎化能力を評価するためのテストベッドとしても機能します。

2.  **Agent Cの有効化と注意選択メカニズムの実装 (Roadmap B-1)**
    F/Gを受動的な「目」として使うだけでなく、**Agent Cを能動的な「脳」として有効化**します。Agent Cが、アフォーダンスの推測に重要だと判断した部分に「注意」を向けるメカニズムを実装することで、受動的な情報処理から能動的な情報収集へと移行します。

3.  **内発的報酬による探索の促進 (Roadmap A-3)**
    Agent Cが未知の形状やインタラクションを積極的に試すよう、**内発的報酬システム**を導入します。例えば、自身の予測誤差（ηの変動など）を「驚き」や「好奇心」の指標とし、それを改善する行動を自ら学習させることで、教師なしでのアフォーダンス発見を促します。

## 5. 結論

Phase 1の学習は、プロジェクトの確かな第一歩ですが、それ単体では「未知の形状への対応」という最終目標を達成することはできません。現在のモデルは、既知の形状を記憶・分類する能力に留まっており、真の汎化能力である「推測」のメカニズムを欠いています。

今後は、Agent Cを主役とし、**「能動的な注意選択」**と**「内発的報酬による探索」**を実装することが、このギャップを埋めるための核心的なステップとなります。
