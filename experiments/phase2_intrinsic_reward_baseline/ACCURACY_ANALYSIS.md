# Phase 2実験における100%精度の批判的分析

Phase 2実験で達成された100%という精度は、一見すると素晴らしい成功に見えるが、その内実を批判的に検討する必要がある。結論から言えば、この数字は**「成功を過剰に表現しており、タスクの単純さに起因するものである」**可能性が高い。

## 1. Accuracy計算の実装上の問題

まず、`run_phase2.py`の`_compute_affordance_accuracy`関数は、精度を正しく測定していない。

```python
# Placeholder: return 1.0 if any segment was visited, else 0.0
return 1.0 if len(predicted) > 0 else 0.0
```

この実装は、Agent Cが**いずれかのセグメントに一度でも注目すれば**、精度を1.0（100%）としてしまう。これは「アフォーダンスを正しく推測したか」を全く評価しておらず、単に「エージェントが何らかの行動をしたか」をチェックしているに過ぎない。

## 2. タスク設定の単純さ

仮にAccuracyの計算が正しかったとしても、100%という結果はタスクの単純さに起因する可能性がある。

### a) 報酬設計が単調すぎる

内発的報酬は `r(t) = α · (η_whole - η_part)` で定義される。これは、**「全体よりも部分の方が、より"既知"の形状に近い」**場合に正の報酬を与える。今回のデータセットでは、複合オブジェクトは全て「既知の基本形状（立方体、円柱、球）」の組み合わせでできているため、部分に注目すれば必ずη_partはη_wholeより小さくなる。つまり、**どの部分に注目しても必ず正の報酬が得られる**ため、エージェントは最適な行動を学習するまでもなく、ランダムな選択でも成功してしまう。

### b) 状態表現が単純すぎる

現在のAgent Cの状態（state）は、オブジェクト全体のグローバルなアフォーダンス特徴量で固定されている。`next_state = state` となっており、エージェントがどの部分に注目しても、次の状態が変化しない。これは、マルコフ決定過程として不完全であり、エージェントは「どの部分に注目したか」という自身の行動の履歴を状態として保持できていない。

## 3. なぜこの結果を「成功」とみなすべきではないのか

この100%という結果を鵜呑みにするのは危険である。これは、アーキテクチャの真の能力を検証したことにはならず、むしろ**実験設計の甘さ**を露呈している。

- **過学習のリスク**: エージェントは、単に「どこかをクリックすれば報酬がもらえる」という短絡的な方策を学習しているだけで、真に形状を理解しているわけではない。
- **汎化能力の欠如**: より複雑な未知の形状（例えば、部分が既知の形状ではない場合）に対しては、この方策は全く機能しないだろう。

## 4. 次のステップ：より挑戦的な実験設計へ

この分析を踏まえ、Phase 2の成功を素直に喜ぶべきではない。むしろ、これを教訓として、より厳密で挑戦的な実験設計を考えるべきである。

1.  **Accuracyの再定義**: `_compute_affordance_accuracy`を、Fが予測したアフォーダンスと、データセットのグラウンドトゥルースを比較するように修正する。

2.  **報酬設計の高度化**: 単純なηの差分だけでなく、「どのくらい珍しい部分か（Novelty）」や「どのくらい予測が難しいか（Prediction Error）」といった要素を報酬に加える。

3.  **状態表現の改善**: Agent Cが自身の行動履歴（どのセグメントに注目したか）を状態に含めるように、リカレントな構造（RNNやTransformer）を導入する。

4.  **より困難なデータセット**: 部分が既知の形状ではない、あるいはノイズが多いデータセットを用意し、エージェントの真の汎化能力を試す。

## 結論

Phase 2の100%という結果は、**「比較η」というコンセプトのポテンシャルを示唆した**という点では価値があるが、これを「成功」と結論付けるのは時期尚早である。むしろ、これは**「我々が解くべき問題の本当の難しさ」**を明らかにしてくれた、価値ある失敗と捉えるべきだ。
