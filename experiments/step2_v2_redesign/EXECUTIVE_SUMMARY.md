# Agent C再設計実験 - エグゼクティブサマリー

## 実験の目的

価値関数分析v3の理論的枠組みに基づき、Functor F/Gの特徴量（affordance + η）をAgent Cに統合することで、強化学習の性能が向上するかを検証した。

## 主要な結果

### 定量的結果

| メトリック | Baseline | F/G-Enhanced | 変化 |
|-----------|----------|--------------|------|
| 最終平均報酬 | 2.69 | -6.22 | **-8.91** ↓ |
| 成功率 | 3% | 0% | **-3%** ↓ |
| 最終平均距離 | 0.45m | 1.27m | **+0.82m** ↑ |
| 訓練時間 | 5.1分 | 67.0分 | **+13倍** |

### 結論

**F/G特徴量の統合は、予想に反してAgent Cの学習を阻害した。**

## 重要な発見

### 1. 環境再設計の成功

以前のStep 2（報酬-84930、成功率0%）から劇的に改善（報酬2.69、成功率3%）。環境設計の重要性が実証された。

**改善点:**
- トルク制御 → 位置制御
- 単純な距離ベース報酬 → 距離改善量ベース報酬
- 貧弱な状態表現 → 豊かな状態表現（end-effector位置、相対ベクトル）

### 2. F/G統合の失敗パターン

学習曲線の分析から、以下の3段階の失敗パターンが観察された。

**初期（0-200エピソード）:** F/G版は急速に改善し、成功率16%に到達（ベースラインは0%）。F/G特徴量が初期探索を加速した。

**中期（200-600エピソード）:** F/G版の性能が崩壊し、報酬が負に転じた。距離が0.5mから2.0mに悪化。

**後期（600-1500エピソード）:** F/G版は回復せず、距離2.0-2.5で停滞。ベースラインは安定して改善を続けた。

### 3. ηの無効性

η（再構成誤差）は3.38-3.40の範囲でほぼ一定であり、Δηは学習信号として機能しなかった。

## 失敗の根本原因

### 表現空間とタスク空間のミスマッチ

**F/Gの表現空間:** 静的な点群から抽出された形状理解（affordance）と握り指標（η）

**Reachingタスクの要求:** 動的な相対位置と速度の制御

このミスマッチが、F/G統合の失敗の主要因と考えられる。F/Gは「物体の形状」を理解するが、Reachingタスクは「物体への到達経路」を必要とする。

## 理論的含意

### 随伴の成立条件の修正

**当初の仮説（価値関数分析v3）:**
> 「F/Gという川床の上をAgent Cという水が流れると、はじめて随伴が成立する」

**実験結果に基づく修正:**
> 「随伴が成立するには、F/Gの表現空間とAgent Cのタスク空間が整合している必要がある」

### 学習可能性の条件

本実験から、以下の条件が学習可能性に必須であることが示唆された。

**条件1: 表現の適合性** - 特徴量がタスクの本質的要求に対応している

**条件2: 次元の適切性** - 状態空間の次元が探索可能な範囲にある（16次元 vs 49次元）

**条件3: 信号の有用性** - 追加特徴量が学習に有用な信号を提供する（ηは提供しなかった）

**条件4: 計算効率** - 訓練時間が実用的範囲にある（5分 vs 67分）

## 次のステップ

### 短期的改善（実装レベル）

**特徴量の選択的使用:** affordanceのみを使用し、ηを除外する。内発的報酬（α_int）を削除する。

**次元削減:** affordanceを8-16次元に圧縮（PCA/Autoencoder）。状態空間を16+8=24次元程度に抑える。

**ハイパーパラメータ調整:** mini_batch_sizeを128に増加、learning_rateを1e-4に減少、clip_epsilonを0.1に減少。

### 長期的方向性（理論レベル）

**タスク適合型F/Gの開発:** 動的な点群（時系列）でF/Gを再訓練し、Reachingタスクに特化したaffordance表現を学習させる。

**階層的アーキテクチャ:** F/Gを高レベル目標設定（「どこに到達するか」）に使用し、Agent Cを低レベル制御（「どう動くか」）に特化させる。

**End-to-end学習:** 点群から直接行動を出力するTransformer-basedアーキテクチャを検討する。

## 教訓

### 成功した点

**環境設計の改善:** 位置制御、改善された報酬関数、豊かな状態表現により、以前の失敗（報酬-84930）から劇的に改善した。

**実験設計の妥当性:** ベースラインとの比較により、F/G統合の効果を明確に評価できた。

**理論的洞察:** 随伴の成立条件（表現空間とタスク空間の整合性）が明確になった。

### 失敗から学んだこと

**表現の適合性が最優先:** 高度な特徴量も、タスクに適合していなければ有害である。

**初期の成功は保証ではない:** F/G版の初期学習（0-200エピソード）は成功したが、長期的には失敗した。

**計算コストの重要性:** 13倍の訓練時間は実用性を著しく損なう。

**ηの再解釈:** ηは静的な形状理解の指標であり、動的な行動制御には無関係である。

## 最終評価

本実験は、F/G統合の「失敗」を示したが、これは理論的枠組みの限界ではなく、**実装の詳細**（特徴量の選択、タスクとの適合性）の重要性を示している。

環境再設計の成功（報酬2.69、成功率3%）は、Agent Cの基本的な学習能力を実証した。F/G統合の失敗は、「随伴の成立には表現空間とタスク空間の整合性が必須である」という重要な理論的洞察をもたらした。

次のステップでは、タスク適合型F/Gの開発、または階層的アーキテクチャの導入により、随伴の成立条件を満たすことが期待される。
