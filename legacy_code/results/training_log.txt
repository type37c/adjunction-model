============================================================
FULL-SCALE TRAINING EXPERIMENT
============================================================
Episodes: 100
Episode length: 10
Unique shapes: 50
Device: cpu
============================================================

Creating synthetic dataset...
  Created 50 shapes

Creating model...
  Model parameters: 1,604,658
  Value function parameters: 61,825

Creating trainer...
  Trainer created (F/G frozen)

Starting training...
------------------------------------------------------------
Episode 10/100
  R_intrinsic: -0.0215
  Value (start): -0.1696
  TD loss: 0.0202
  Coherence: 0.4469
  Valence: 0.0000
Episode 20/100
  R_intrinsic: -0.0194
  Value (start): -0.2304
  TD loss: 0.0116
  Coherence: 0.4209
  Valence: 0.0000
Episode 30/100
  R_intrinsic: -0.0186
  Value (start): -0.0992
  TD loss: 0.0141
  Coherence: 0.4294
  Valence: 0.0000
Episode 40/100
  R_intrinsic: -0.0150
  Value (start): -0.3440
  TD loss: 0.0031
  Coherence: 0.4362
  Valence: 0.0000
Episode 50/100
  R_intrinsic: -0.0145
  Value (start): -0.1908
  TD loss: 0.0267
  Coherence: 0.4290
  Valence: 0.0000
Episode 60/100
  R_intrinsic: -0.0148
  Value (start): -0.1004
  TD loss: 0.0022
  Coherence: 0.4366
  Valence: 0.0000
Episode 70/100
  R_intrinsic: -0.0119
  Value (start): -0.1157
  TD loss: 0.0199
  Coherence: 0.4359
  Valence: 0.0000
Episode 80/100
  R_intrinsic: -0.0076
  Value (start): -0.3031
  TD loss: 0.0049
  Coherence: 0.4207
  Valence: 0.0000
Episode 90/100
  R_intrinsic: -0.0019
  Value (start): -0.2070
  TD loss: 0.0029
  Coherence: 0.4286
  Valence: 0.0000
Episode 100/100
  R_intrinsic: 0.0245
  Value (start): 0.0265
  TD loss: 0.0099
  Coherence: 0.4366
  Valence: 0.0000
------------------------------------------------------------
Training complete!

Saving results...
Metrics saved to results/full_scale_training/metrics.json
Intrinsic rewards plot saved to results/full_scale_training/intrinsic_rewards.png
Value function plot saved to results/full_scale_training/value_function.png
Agent state plot saved to results/full_scale_training/agent_state.png
============================================================
FULL-SCALE TRAINING EXPERIMENT REPORT
============================================================

Summary Statistics:
------------------------------------------------------------
  Total Episodes: 100.0000
  Final Intrinsic Reward: 0.0245
  Final Value (Start): 0.0265
  Final TD Loss: 0.0099
  Final Coherence: 0.4366
  Final Valence: 0.0000

Trends:
------------------------------------------------------------
  r_intrinsic: -0.0215 → 0.0087 (Δ +0.0302)
  value_start: -0.1591 → 0.0125 (Δ +0.1716)
  avg_coherence: 0.4328 → 0.4320 (Δ -0.0007)
  avg_valence: 0.0000 → 0.0000 (Δ +0.0000)

============================================================

Report saved to results/full_scale_training/report.txt

Model saved to results/full_scale_training/model_final.pt

============================================================
EXPERIMENT COMPLETE
============================================================
