# Phase 2 実験設計書 — 要約

## 目的
Agent Cが、比較η（Comparative η）のメカニズムを手がかりとして、未知の複合的形状の構造を分解的に理解し、その部分ごとに適切なアフォーダンスを推測できるかを検証する。

## 核心的な仮説
> Agent Cは、オブジェクト全体に対する再構成誤差（η_whole）と、自身の注意選択によってフォーカスした部分に対する再構成誤差（η_part）とを比較することで得られる内発的報酬（η軌跡の改善）に基づき、未知の形状を既知の構成要素へと分解する最適な注意選択方策を学習できる。

## Agent Cのアーキテクチャ変更

### 注意選択の行動空間
- **状態空間**: P_whole（全体の点群）、P_part（注意対象部分の点群）、過去のη軌跡
- **行動空間**: {a_1, a_2, ..., a_n} — オブジェクトの事前定義セグメントに注意を向ける行動

### 比較ηの計算メカニズム
1. **η_whole**: オブジェクト全体の点群をF/Gに入力した際の再構成誤差
2. **η_part**: Agent Cが選択した部分点群をF/Gに入力した際の再構成誤差

| 状況 | η_whole | η_part | 解釈 |
|---|---|---|---|
| 既知の形状 | 低い | 低い | 全体と部分が整合。既知の構造。現状維持 |
| 未知の組み合わせ | 高い | 低い | 全体は未知だが、この部分は既知の何かに似ている。良い軌跡。この注意選択を強化 |
| 無関係な部分 | 低い | 高い | この部分に注目すると理解が悪化する。悪い軌跡。この注意選択を抑制 |

## 内発的報酬の設計
```
r(t) = α · (η_whole(t) - η_part(t))
```
- η_wholeが高く（全体が未知で）かつη_partが低い（部分が既知である）ような注意選択を探すよう動機付けられる
- これは「好奇心」の形式的な表現

## 訓練プロトコル
- **F/Gパラメータの凍結**: F/Gは完全に凍結。学習の主体はAgent Cのみ
- **学習アルゴリズム**: Deep Q-Network (DQN) や Soft Actor-Critic (SAC) などの深層強化学習アルゴリズム

## 評価方法
- 学習済みAgent Cに未知形状を提示
- 複数回の注意選択行動を通じて、各部分のF/Gアフォーダンス予測が人間の正解ラベルと一致するかを評価
- Precision、Recall、F1スコアで定量評価

## 期待される結果
- Agent Cが未知の形状（例：取っ手付き立方体）に対して、まず全体を見て高いη_wholeを観測した後、注意を「立方体部分」と「取っ手部分」に順番に切り替える
- 「立方体部分」→ stackable, graspable、「取っ手部分」→ graspable を予測

## 失敗条件
- Agent Cの注意選択がランダムなまま収束せず、特定の構造を発見できない
- Agent Cが単一の部分に固執し、オブジェクト全体を探求する行動が生まれない
- 最終的なアフォーダンス予測の精度が、ランダムベースラインを有意に上回らない
