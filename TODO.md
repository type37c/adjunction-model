# TODOリスト

**最終更新:** 2026年2月19日

## 現在のフォーカス: Phase 1.5（F/Gの改修と再訓練）

### 🔥 最優先タスク

- [ ] **FunctorF_v2の実装**
  - [ ] 近傍構造の導入（k-NN + 局所特徴抽出）
  - [ ] 目的条件付けの実装（FiLM変調）
  - [ ] 単体テストの作成
  - [ ] Phase 1チェックポイントとの互換性確認

- [ ] **Phase 1.5訓練データの収集**
  - [ ] PyBulletで「形状 + 行動 → 結果」のデータ生成スクリプト
  - [ ] 行動の種類: 押す、引く、回転、持ち上げる、倒す
  - [ ] オブジェクトの種類: box, cylinder, sphere, cup, bowl
  - [ ] データセットサイズ: 各組み合わせ100エピソード

- [ ] **Phase 1.5の訓練ループ**
  - [ ] 再構成損失 + 行動予測損失の実装
  - [ ] 訓練スクリプトの作成
  - [ ] 訓練の実行（目標: 2-3時間）

- [ ] **Step 1の再実行と検証**
  - [ ] 再訓練後のF/Gでηの挙動を再測定
  - [ ] 改善の定量的評価（変動係数、行動種類による差）
  - [ ] 結果のドキュメント化

---

## Phase 1.5: F/Gの改修と再訓練

### 完了したタスク ✅
- [x] Step 1「ηの物理的意味の検証」実験 (2026-02-18完了)
- [x] Step 1の問題診断（Z座標フィルタリング、訓練データ不一致） (2026-02-18完了)
- [x] Step 1の修正と再実行 (2026-02-18完了)
- [x] 哲学的理論の調査（Heidegger, Merleau-Ponty, Gibson, SIF, FEP） (2026-02-19完了)
- [x] Module M（目的機構）の設計 (2026-02-19完了)
- [x] READMEとTODOの更新 (2026-02-19完了)

### 進行中のタスク 🔄
- [ ] FunctorF_v2の実装
- [ ] Phase 1.5訓練データの収集

### 今後のタスク 📋
- [ ] FunctorG_v2の実装（必要に応じて）
- [ ] Phase 1.5の評価指標の設計
- [ ] Phase 1.5の結果分析とドキュメント化

---

## Phase 2.1: Agent Cとの統合

### Module Mの実装
- [ ] **Concern State**の実装
  - [ ] GRUベースの関心状態更新
  - [ ] 基本的な関心の初期化（自己維持に相当）
  - [ ] 関心状態の可視化ツール

- [ ] **Grip Monitor**の実装
  - [ ] ηの変化パターンの統合
  - [ ] 行動結果のフィードバック処理
  - [ ] 把握度の履歴管理（GRU）
  - [ ] 最適からの逸脱度の計算

- [ ] **Salience Modulator**の実装
  - [ ] 注意機構（Multi-head Attention）
  - [ ] Concern Stateからクエリへの射影
  - [ ] アフォーダンスランドスケープからフィールドへの変換
  - [ ] 顕著性重みの可視化

### Agent Cの改修
- [ ] Agent CとModule Mの統合
  - [ ] 平均プーリングをSalience Modulatorに置換
  - [ ] Grip MonitorからのフィードバックをAgent Cに接続
  - [ ] end-to-endの計算グラフの構築

### 訓練と評価
- [ ] Phase 2.1の訓練ループ
  - [ ] 損失関数の実装（再構成 + タスク + 把握度 + 多様性）
  - [ ] カリキュラム学習の設計（λの動的調整）
  - [ ] 訓練スクリプトの作成

- [ ] Phase 2.1の評価
  - [ ] F/G特徴を使う vs 使わないAgent Cの比較
  - [ ] 学習速度の比較
  - [ ] タスク達成率の比較
  - [ ] Concern Stateの進化の可視化

---

## Phase C: 発展的課題（長期）

### 随伴の理論的拡張
- [ ] Module M導入後の三角恒等式の検証
- [ ] 目的を通した随伴の形式化
- [ ] 圏論的な正当性の証明

### 軌跡ベースの認知機能
- [ ] 軌跡メモリの実装
- [ ] エピソード記憶の統合
- [ ] 時間的文脈の利用

### 言語との統合
- [ ] アフォーダンスの言語的記述
- [ ] 言語による目的の指定
- [ ] 言語を通した知識の伝達

### 抽象思考の実装
- [ ] 階層的な目的構造（in-order-to → for-which → for-the-sake-of-which）
- [ ] メタ認知の実装
- [ ] 反省的思考の実装

---

## ドキュメント・メンテナンス

### 完了 ✅
- [x] README.mdの更新（哲学的基盤、Module M、Step 1の発見） (2026-02-19完了)
- [x] TODO.mdの更新（Phase 1.5タスクの詳細化） (2026-02-19完了)

### 今後のタスク 📋
- [ ] ARCHITECTURE.mdの更新（Module Mの追加）
- [ ] ROADMAP.mdの更新（Phase 1.5とPhase 2.1の詳細）
- [ ] 実験結果の統合ドキュメントの作成
- [ ] コードのドキュメンテーション（docstring）の充実

---

## バグ・技術的負債

### 既知の問題
- [ ] Phase 1のF/Gが視点変化に過敏（Step 1で確認）
- [ ] 平均プーリングが局所構造を消失させる
- [ ] エピソードリセットの設計が未確定（Concern Stateをリセットすべきか？）

### 改善が必要な箇所
- [ ] データ前処理のパイプラインの統一
- [ ] チェックポイントの保存・読み込みの標準化
- [ ] 実験結果の可視化ツールの整備
- [ ] ユニットテストの追加

---

## メモ

### Phase 1.5の設計判断
- **近傍構造のk値**: 16を初期値とする（調整可能）
- **目的ベクトルの次元**: 16を初期値とする
- **行動の種類**: 5種類（push, pull, rotate, lift, topple）
- **訓練データサイズ**: 5オブジェクト × 5行動 × 100エピソード = 2500エピソード

### Phase 2.1の設計判断
- **Concern Stateの次元**: 32を初期値とする
- **Grip Monitorの隠れ層**: 128を初期値とする
- **Salience Modulatorのヘッド数**: 4を初期値とする
- **損失関数の初期重み**: λ_recon=1.0, λ_task=1.0, λ_grip=0.5, λ_div=0.1

### 哲学的対応の確認
各コンポーネントが哲学的概念に対応していることを常に意識する：
- Concern State ↔ Worumwillen（ハイデガー）
- Grip Monitor ↔ 最大把握（メルロ＝ポンティ）
- Salience Modulator ↔ フィールド（SIF）
- η ↔ 不調和度（Bruineberg/Rietveld）
