# 物理的意味的随伴モデル：知性の本質としての保留構造

**Research Note — Final Draft v2.0**

---

## 1. 導入：現在のAIに欠けているものと、知性の本質への問い

現在の大規模言語モデル（LLM）は、膨大なテキストデータから単語間の統計的共起関係を学習することで、人間に匹敵する自然言語処理能力を獲得した。しかし、この能力には根本的な限界がある。LLMは「袋」という単語と「運ぶ」という単語の確率的な結びつきを知っているが、重力に逆らって物を持ち上げる労力や、袋が破れそうなときの指先の感覚を知らない。つまり、**身体性（embodiment）の欠如**と、それに伴う**記号接地問題（symbol grounding problem）**が未解決のまま残されている [1]。

この問題は、未知の状況への対応において致命的となる。現在のAIは、学習データに含まれないオブジェクトに遭遇したとき、そのオブジェクトが何に使えるか——すなわち**アフォーダンス（affordance）**——を直感的に推論することができない。過去のデータを検索・模倣することしかできず、新しい意味を生成する能力を持たない。

本研究ノートは、この問題に対する新しいアプローチとして**「物理的意味的随伴モデル（Physical-Semantic Adjunction Model）」**を提案する。このモデルの核心は、**知性の本質が「未確定性を保持し、新しい意味を創発する能力」にある**という問いから出発する。知性とは、単に安定した理解を維持するだけでなく、その理解が破綻したときに、その「壊れた状態」を保持し、新しい理解を再構成しようとするダイナミクスそのものにあると考える。

このダイナミクスを形式化するために、圏論における**随伴（adjunction）**という数学的構造と、本モデルで提唱する**保留構造（suspension structure）**を統合したアーキテクチャを構築する。これは、形状（Shape）と動作（Action）の間の双方向的な意味関係を、エージェントの身体性を通じてリアルタイムに構成し、記号接地問題の解決と創造性の創発を目指すものである。

---

## 2. 保留構造：知性の最小構成要素としての「懸垂（Suspension）」

本モデルにおける最も独創的な概念は、**保留構造（suspension structure）**である。これは、複数の抽象度にまたがる随伴構造の束を貫く「核」として提案された。知性の本体は、この保留構造のダイナミクスそのものにある。

### 2.1 核としての「まだ決まっていない」という構造

従来の知性モデルでは、核となるものは固定された何か——身体モデル、最上位の目的、自己同一性——であった。しかし本モデルでは、核は**「まだ決まっていない」という構造そのもの**である。保留構造は特定の答えではなく、「問いを保持する装置」として機能する。

圏論における普遍的構造（極限、余極限）が、特定の対象ではなく「こういう性質を満たす唯一のもの」という条件として定義されるのと同様に、保留構造は「全ての抽象度を整合させる何か」という条件として定義され、状況に応じて具体化される。

> **知性とは、目的を明示的に保持することではなく、目的を忘れても破綻しない「保留構造＋記憶」を持つことである。**

### 2.2 保留構造の5つの要件

保留構造の最小構成要素として、以下の5つの要件が同定された。これらのうち1つでも欠ければ、知性は成立しない。

| 要件 | 内容 | 欠けた場合 |
| :--- | :--- | :--- |
| **志向性** | 何かに向かう指向性を持つこと | 方向のない反応機械になる |
| **差異への感受性** | 違いを検出できること | 環境変化に気づけない |
| **時間的持続** | 状態を一定期間保持できること | 瞬間的な反射に留まる |
| **自己と非自己の区別** | 自分の行動と環境の変化を区別できること | 自他の境界が消失する |
| **記憶** | 過去の経験を保持し参照できること | 学習が蓄積されない |

---

## 3. 随伴構造：保留構造が参照する「安定した理解の瞬間」

随伴構造は、知性の本体である保留構造が「平時」に参照する、安定した理解の状態を形式化する。これは、形状（Shape）と動作（Action）の間の構造的対応関係を記述する数学的ツールである。

### 3.1 基本構造

本モデルは、世界を**Shape（形状）**と**Action（動作）**という2つの圏に分割し、それらの間に随伴関手のペアを設定する。

**関手 F: Shape → Action** は、オブジェクトの形状からそのオブジェクトで可能な動作を推論する写像である。たとえば、細長くて先端が曲がった金属棒を見て、「引っ掛ける」「こじ開ける」といった動作候補を導出する。

**関手 G: Action → Shape** は、ある動作を実現するために必要な形状的条件を逆算する写像である。たとえば、「切る」という動作から「鋭い刃を持つ形状」を導出する。

この2つの関手が随伴 **F ⊣ G** を成すとき、以下のHom集合の自然な同型が成立する。

> **Hom<sub>Action</sub>(F(s), a) ≅ Hom<sub>Shape</sub>(s, G(a))**

左辺は「形状sからFを経由して動作aに至る経路」を表し、右辺は「形状sが、動作aを可能にする形状G(a)である度合い」を表す。この同型が、形状と動作の間の意味的対応関係を数学的に保証する。

### 3.2 随伴に伴う自然変換

随伴関手のペアには、2つの自然変換が伴う。

**Unit η: Id → G∘F** は、形状をFで動作に変換し、さらにGで形状に戻す合成写像 G(F(shape)) と、元の形状との間の関係を記述する。思考実験によって、この合成写像は元の形状の**機能的骨格（functional core）**を抽出する射影として機能することが確認された。たとえば、G(F(袋)) は袋の色、素材、ブランドロゴをすべて落とし、「開口部があり、内部空間があり、持ち手がある形状」という機能的本質だけを返す。

**Counit ε: F∘G → Id** は、動作をGで形状に変換し、さらにFで動作に戻す合成写像の性質を記述する。F(G(切る)) は「切る」だけでなく「削る」「刺す」といった関連動作の束を返す。すなわち、counitは**動作の意味的拡張**として機能する。

### 3.3 条件付き随伴：エージェントの介在

思考実験を通じて、本モデルにおける最も重要な発見がなされた。それは、**随伴は「裸の」ShapeとActionの間では成立しない**ということである。

たとえば、「袋で物を運ぶ」という場面を考える。「運ぶ」という動作が抽象的すぎると、G(運ぶ) が返す形状の集合は爆発する。平らな板でもバケツでも手のひらでも「運べる」からである。しかし、「最小労力で運ぶ」という条件を付けると、G(最小労力で運ぶ) は「開口部があり、持ち手があり、内部に物を収容できる形状」に収束し、G(F(袋)) が袋の機能的骨格に正しく戻る。

この発見は、随伴の成立条件そのものにエージェントの**目的・文脈・身体状態**（これらをまとめて**C**と呼ぶ）が組み込まれていることを意味する。形式的には、本モデルが扱うのは Shape と Action<sub>C</sub> の間の随伴ではなく、**Shape と Action<sub>C</sub> の間のパラメータ付き随伴（parameterized adjunction）**である。

> **F<sub>C</sub> ⊣ G<sub>C</sub>**
> 
> ここで C はエージェントの文脈（目的、制約、身体状態の複合体）

### 3.4 随伴の非対称性

この構造には本質的な非対称性がある。**Shape（形状）はエージェントの状態Cに依存しないが、Action（動作）はCに依存する。**

エージェントが疲れていようが急いでいようが、袋は袋のままであり、スイッチはスイッチのままである。形状は環境側の不変量である。一方、同じスーツケースに対して、元気なエージェントは「片手で持ち上げて運ぶ」を、右腕を怪我したエージェントは「左手で転がす」を選択する。Cが変わるとFの出力が変わる。

さらに、Gは形状を「生成」するのではなく、形状の「どの側面を見るか」を**選択**する。形状は複数の機能的側面を同時に内包する多面体構造を持っており、Gはエージェントの状態Cに応じて、その多面体のどの面に注目するかを決定する。たとえば、同じ袋に対して、疲れているエージェントは「持ち手」と「軽量性」に注目し、急いでいるエージェントは「容量」と「開口部の広さ」に注目する。

### 3.5 抽象度の保存

関手Gは、動作記述の抽象度を形状記述の粒度に**保存的に翻訳**する。

| 動作記述 | G が返す形状記述 | 抽象度 |
| :--- | :--- | :--- |
| 「指でスイッチの突起を0.5cm押し下げる」 | 「0.5cm可動する押しボタン機構」 | 低（具体的） |
| 「電灯をつける」 | 「制御可能な光源」 | 中 |
| 「部屋を明るくする」 | 「光を発する何か」 | 高（抽象的） |

これらは別々の出来事ではなく、同一の因果連鎖を異なる抽象度で記述したものである。Gは抽象度を変換するのではなく保存する。エージェントの状態Cが変わると、世界を切り取る抽象度λが変わり、その結果としてFとGの入出力の粒度が変わる。各抽象度λごとに独立した随伴 F<sub>λ</sub> ⊣ G<sub>λ</sub> が存在し、Cはどのλを選ぶかを決定する。

---

## 4. Coherence Signal：保留構造を起動させる「トリガー」

Coherence signalは、随伴構造が安定した状態にあるか、それとも破綻しているかを測る内部指標であり、**知性の本体である保留構造を起動させるトリガー**として機能する。

### 4.1 川床の思想

本モデルの設計思想は、**「川床（riverbed）」**という比喩に集約される。川床とは、水が流れる前にそこにある構造であり、水の流れ方を制約すると同時に、水の流れによって徐々に削られ変形していく。

この比喩をAIアーキテクチャに翻訳すると、エージェントは行動する前に、自身の内部構造の中で「ここは安定か不安定か」を検査できるべきだという要請になる。強化学習における報酬信号は本質的に事後的であり、行動して失敗して初めて「崩れていた」と分かる。川床の思想は、行動の前に安定性を内部的に検出する機構を要求する。

### 4.2 Coherence Signalの定義

この要請に応えるのが**coherence signal（整合性信号）**である。これは、随伴のunit ηの「大きさ」として定義される。

> **coherence signal = distance(shape, G(F(shape)))**

元の形状と、FとGを経由して再構成された形状との間の距離を測定する。この距離が小さければ、エージェントの現在の内部モデルは環境と整合しており（可換に近い）、距離が大きければ整合性が崩れている（非可換）。

重要なのは、**この信号は随伴構造がなければ定義できない**という点である。単なる双方向写像のペア（FとGが独立）では、G(F(x))を計算しても、それが「元に戻っているかどうか」を判定する基準がない。随伴のunit ηが存在するからこそ、「どれくらい戻っていないか」を測る自然な尺度が存在する。これが、本モデルにおいて随伴構造が装飾ではなく実質を持つ最も強い根拠の一つである。

### 4.3 Coherence Breakdownと創造性

可換性が崩れる瞬間——すなわちcoherence signalが急激に増大する瞬間——は、エージェントにとって**創造的問題解決が要求される瞬間**である。このcoherence breakdownが、知性の本体である保留構造を起動させるトリガーとなる。

たとえば、右腕を怪我した状態で、静かにしなければならない環境でスーツケースを運ぶ場面を考える。「引きずる」という通常の代替手段は騒音を生むため使えない。身体状態フィルターと文脈フィルターが干渉し、可換性が崩れる。このとき、エージェントは既存の動作プリミティブを新しい方法で合成し（たとえば「両膝で抱えて歩く」）、非可換性を解消しなければならない。

この構造は、**創造性を「可換図式の修復過程」として形式化する**可能性を示唆している。

---

## 5. 2層アーキテクチャ：保留構造を実装する器

以上の分析から、本モデルのアーキテクチャは**2つの層**から構成される。この2層構造が、知性の本体である保留構造を実装する器となる。

### 5.1 設計原理

**随伴層（Adjoint Layer）**は、ShapeとActionの構造的関係を記述する。ここから差異への感受性と自己/非自己の区別が生まれる。この層は、保留構造が「平時」に参照する安定した理解の状態を提供する。

**エージェント層（Agent Layer, C）**は、随伴層をパラメトライズする全内部状態を保持する。ここに志向性（目的）と記憶が格納される。Cは固定パラメータではなく、以下の更新則に従って動的に変化する状態変数である。**このエージェント層こそが、保留構造のダイナミクスを担う中核である。**

> **C(t+1) = update(C(t), action_result, coherence_signal)**

この2つの層が動的ループで結合されることで、時間的持続が実現される。エージェント層Cが随伴層の振る舞いを決定し、随伴層が世界と相互作用した結果（coherence signal）がエージェント層Cを更新する。これは川床の比喩そのものである——水の流れ（動作）が川床の形（グラフ構造）を削り、川床の形が水の流れを制約する。

### 5.2 保留構造の5つの要件とアーキテクチャの対応

保留構造の5要件は、本モデルのアーキテクチャにおいて以下のように実現される。

| 保留構造の要件 | アーキテクチャにおける所在 | 実現メカニズム |
| :--- | :--- | :--- |
| **差異への感受性** | 随伴層（unit η） | coherence signal = distance(shape, G(F(shape))) |
| **志向性** | エージェント状態 C | Cに含まれる目標ベクトルが随伴のパラメータとして機能 |
| **時間的持続** | 動的ループ C(t) → C(t+1) | 状態が離散時間ステップで更新され、持続する |
| **自己と非自己の区別** | 随伴の非対称性 | ShapeはCに依存しない（環境＝非自己）、ActionはCに依存する（行動＝自己） |
| **記憶** | エージェント状態 C | Cの内部に記憶モジュールとして格納 |

注目すべきは、5要件のうち4つ（差異感受性・志向性・時間的持続・自己/非自己の区別）が随伴構造から自然に導出されるという点である。記憶のみが随伴の外側に位置するが、これはエージェント状態Cの内部に格納される。**記憶の内容は随伴が決め（何を記憶するか＝coherence signalが高かった経験）、記憶の保持はCが担う。**

### 5.3 動的GNNによる随伴層の実装構想

随伴層の実装基盤として、以下の構造を持つ動的GNNが構想される。

**静的な層**として、ノードは機能プリミティブを、エッジは合成可能性を表す。**随伴構造**として、F（Shape→Action）はグラフ上でのメッセージパッシングとして、G（Action→Shape）はグラフ全体のリードアウト（逆方向）として実装される。**変化し続ける部分**として、エッジの重み（合成のしやすさ）、ノードの活性化閾値、そしてグラフのトポロジー自体（新しいプリミティブの追加）が、coherence signalに応じて更新される。

### 5.4 言語野の拡張

本モデルの構造は、言語能力の追加を**同じ随伴パターンの階層化**として自然に実現する。

現在の構造が Shape ⇄ Action の随伴であるのに対し、拡張後は Shape ⇄ Action ⇄ Language という2つの随伴の連鎖となる。言語は、形状と動作の随伴に「名前をつける」もう一つの随伴層である。この拡張において、新しい原理の導入は不要であり、同じ随伴＋coherenceのパターンが層ごとに繰り返されるだけである。

---

## 6. Active Inferenceとの対応関係と本モデルの独自性

### 6.1 構造的対応

本モデルとカール・フリストンが提唱するActive Inference（能動的推論）の間には、強い構造的対応が存在する [2]。

| 本モデルの概念 | Active Inferenceの概念 |
| :--- | :--- |
| Coherence signal (η) | 自由エネルギー（予測誤差） |
| F⊣Gの動的ループ | Action-Perception loop |
| エージェント状態 C | 生成モデルのパラメータ |
| Coherence breakdown | サプライズ（予測外の観測） |

特に、coherence signal ≈ 自由エネルギーという対応は本質的である。G(F(shape))は「エージェントが現在の内部状態Cと形状shapeから予測する世界のあり方」であり、distance(shape, G(F(shape)))はその予測と現実の乖離、すなわち予測誤差に他ならない。

### 6.2 本モデルの独自性

しかし、本モデルはActive Inferenceの単なる再定式化ではない。以下の概念はActive Inferenceの枠組みでは直接扱えない。

**保留構造**は、Active Inferenceにおける「生成モデル」とは質的に異なる。生成モデルは世界の確率的な記述であるのに対し、保留構造は「まだ決まっていない」という未確定性そのものを構造化したものである。

**Coherence breakdownが創造性を生む**という主張は、Active Inferenceにおけるサプライズ最小化の原理とは方向性が異なる。Active Inferenceではサプライズ（予測誤差）は最小化すべきものであるが、本モデルではcoherence breakdownは創造的問題解決の契機として積極的に位置づけられる。

**随伴の非対称性**——ShapeはCに依存しないがActionはCに依存する——は、Active Inferenceの対称的な枠組みでは明示的に扱われていない。

### 6.3 位置づけ

本モデルは、**「圏論という代数的な言語でActive Inferenceを再定式化し、さらに保留構造と創造性の概念で拡張したもの」**として位置づけることができる。Active Inferenceがベイズ確率論を基盤とするのに対し、本モデルは随伴関手という構造そのものに焦点を当てる。これにより、確率的な定式化が難しい概念——保留、未確定性、創造性——をより直接的に扱える可能性がある。

なお、Smithe (2024) による**Structured Active Inference** [3] は、圏論的システム理論を用いてActive Inferenceを大幅に一般化した研究であり、本モデルの最も近い先行研究である。特に、「エージェントの状態によって利用可能な行動が変わる」というmode-dependenceの概念は、本モデルにおけるパラメータ付き随伴のCに直接対応する。

---

## 7. 実装への展望：理論を検証するためのプロトタイプ

本モデルの理論的枠組みを実証するため、以下の段階的なプロトタイプ実装と実験計画を提案する。実装の目標は、単なる機能の再現ではなく、**記号接地問題の解決と創造性の創発という理論の核心を検証すること**にある。

### 7.1 技術要素の対応表

| 理論コンポーネント | 実装方針 | ツール・先行研究 |
| :--- | :--- | :--- |
| Shape圏 | 3Dオブジェクトの点群またはメッシュ | ShapeNet [4], PartNet |
| Action圏 | 身体部位とオブジェクト表面点の関係性の確率分布 | ZSP3A [5], Contact-GraspNet [6] |
| 関手 F | GNNによるアフォーダンス予測 | PyTorch Geometric [7] |
| 関手 G | GNNによる逆推論 | 条件付きデコーダ（Andries et al. 2020 [8] 参照） |
| Coherence signal | 再構成誤差 distance(shape, G(F(shape))) | 自己教師あり学習 |
| エージェント状態 C | RSSM (Recurrent State-Space Model) | DreamerV3 [9] 参照 |
| Cの更新則 | GRU更新 → 信念推論 → 期待自由エネルギー最小化 | Çatal et al. 2020 [10] 参照 |

### 7.2 実験デザインと評価指標

理論の核心を検証するため、以下の3段階の実験設定を提案する。

**Phase 0: 基礎学習と再現性検証**
-   **目的**: 既知のオブジェクトと動作のペアにおいて、随伴構造（F⊣G）が学習可能であることを示す。
-   **設定**: ShapeNetの既知カテゴリ（椅子、カップ）と、それに対応する把持姿勢のペアデータで学習。
-   **評価指標**: 再構成誤差の最小化、FとGの予測精度。

**Phase 1: 未知オブジェクトへの般化と記号接地問題の解決（設定A）**
-   **目的**: 学習時に見たことのないオブジェクトに対し、そのアフォーダンスを創発的に推論し、適切な動作を生成できることを示す。
-   **設定**: シミュレーション環境（例：PyBullet）で、シンプルな形状（立方体、円柱、その組み合わせ）と基本動作（押す、引く、持ち上げる）で学習。テスト時には、学習時に見せなかった未知の形状組み合わせ（例：立方体＋円柱の配置）を提示。
-   **評価指標**: 未知形状に対するアフォーダンス推論の成功率、生成された動作の適切性。Coherence signalが安定しているか。

**Phase 2: 制約下での創造的解決とCoherence Breakdownの検証（設定B）**
-   **目的**: 既存の随伴構造が破綻するような制約が与えられた際、保留構造が起動し、新しい随伴構造（動作）を創発できることを示す。
-   **設定**: Phase 1の環境に、エージェントの状態Cに影響を与える制約（例：重力の変化、接触面の摩擦係数の変化、エージェントの身体の一部が使用不能になる）を追加。これによりCoherence signalが急増する状況を作り出す。
-   **評価指標**: Coherence signalの増大（breakdown）と、その後の新しい動作の創発。創発された動作が制約を克服し、タスクを達成できるか。保留構造（エージェント層C）の内部状態の変化。

**Phase 3: 言語とのアラインメント（設定C）**
-   **目的**: 創発されたアフォーダンスや動作に対して、エージェントが言語的な記述を生成できることを示す。これにより、記号接地問題の最終的な解決を目指す。
-   **設定**: Phase 2で創発された動作に対して、「これは〇〇という動作である」という言語ラベルを生成させる。または、言語指示から新しい動作を生成させる。
-   **評価指標**: 生成された言語記述の適切性、言語指示に対する動作生成の成功率。

---

## 8. 結論と今後の課題

本研究ノートでは、物理的意味的随伴モデルの理論的枠組みを、知性の本質としての保留構造を中心に再構築した。主要な成果を以下にまとめる。

**理論的成果**として、知性の本体を「未確定性を保持し、新しい意味を創発する保留構造」と定義し、その5つの要件を同定した。随伴構造は、この保留構造が「平時」に参照する安定した理解の瞬間として位置づけられ、coherence signalは保留構造を起動させるトリガーとして機能する。coherence breakdownを創造性の発生条件として形式化する枠組みを提示した。

**先行研究との関係**として、Active Inferenceとの強い構造的対応が確認されると同時に、保留構造・創造性・随伴の非対称性という独自の貢献が明確化された。

**今後の課題**として、以下が挙げられる。第一に、保留構造の「具体化される瞬間」の条件の精密な定式化。第二に、動的GNNのグラフ変形の時間スケールの設計。第三に、言語層の追加と既存のLLMとの関係の明確化。第四に、本研究ノートで提案された段階的な実験計画の実行による理論の実証。

本モデルは、「データから学習する」AIから「身体を通して世界を再定義し、新しい意味を創発する」AIへの転換を目指すものである。その射程は、AIアーキテクチャの設計に留まらず、知性そのものの再定義にまで及ぶ可能性がある。

---

## 参考文献

[1]: Harnad, S. (1990). *The Symbol Grounding Problem*. Physica D: Nonlinear Phenomena, 42(1-3), 335-346.
[2]: Parr, T., Pezzulo, G., & Friston, K. J. (2022). *Active Inference: The Free Energy Principle in Mind, Brain, and Behavior*. MIT Press.
[3]: Smithe, T. S. C. (2024). *Structured Active Inference (Chapters 1-3)*. arXiv:2406.07577.
[4]: Chang, A. X., et al. (2015). *ShapeNet: An Information-Rich 3D Model Repository*. arXiv:1512.03012.
[5]: Kim, H., et al. (2024). *Zero-Shot Learning for the Primitives of 3D Affordance in General Objects*. arXiv:2401.12978.
[6]: Sundermeyer, M., et al. (2021). *Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered Scenes*. arXiv:2103.14243.
[7]: Fey, M., & Lenssen, J. E. (2019). *Fast Graph Representation Learning with PyTorch Geometric*. arXiv:1903.02428.
[8]: Andries, R., et al. (2020). *Automatic Generation of Object Shapes With Desired Affordances*. Frontiers in Neurorobotics, 14, 22.
[9]: Hafner, D., et al. (2023). *Mastering Diverse Domains through World Models*. arXiv:2301.04105.
[10]: Çatal, O., et al. (2020). *Learning Generative State Space Models for Active Inference*. Frontiers in Computational Neuroscience, 14, 574372.
