# 物理的意味的随伴モデル：身体性・意味理解・創造性の圏論的統合

**Research Note — Draft v1.0**

---

## 1. 導入：現在のAIに欠けているもの

現在の大規模言語モデル（LLM）は、膨大なテキストデータから単語間の統計的共起関係を学習することで、人間に匹敵する自然言語処理能力を獲得した。しかし、この能力には根本的な限界がある。LLMは「袋」という単語と「運ぶ」という単語の確率的な結びつきを知っているが、重力に逆らって物を持ち上げる労力や、袋が破れそうなときの指先の感覚を知らない。つまり、**身体性（embodiment）の欠如**と、それに伴う**記号接地問題（symbol grounding problem）**が未解決のまま残されている。

この問題は、未知の状況への対応において致命的となる。現在のAIは、学習データに含まれないオブジェクトに遭遇したとき、そのオブジェクトが何に使えるか——すなわち**アフォーダンス（affordance）**——を直感的に推論することができない。過去のデータを検索・模倣することしかできず、新しい意味を生成する能力を持たない。

本研究ノートは、この問題に対する新しいアプローチとして**「物理的意味的随伴モデル（Physical-Semantic Adjunction Model）」**を提案する。このモデルは、圏論における**随伴（adjunction）**という数学的構造を用いて、形状（Shape）と動作（Action）の間の双方向的な意味関係を、エージェントの身体性を通じてリアルタイムに構成するアーキテクチャである。

---

## 2. コア理論：形と動作の随伴構造

### 2.1 基本構造

本モデルは、世界を**Shape（形状）**と**Action（動作）**という2つの圏に分割し、それらの間に随伴関手のペアを設定する。

**関手 F: Shape → Action** は、オブジェクトの形状からそのオブジェクトで可能な動作を推論する写像である。たとえば、細長くて先端が曲がった金属棒を見て、「引っ掛ける」「こじ開ける」といった動作候補を導出する。

**関手 G: Action → Shape** は、ある動作を実現するために必要な形状的条件を逆算する写像である。たとえば、「切る」という動作から「鋭い刃を持つ形状」を導出する。

この2つの関手が随伴 **F ⊣ G** を成すとき、以下のHom集合の自然な同型が成立する。

> **Hom<sub>Action</sub>(F(s), a) ≅ Hom<sub>Shape</sub>(s, G(a))**

左辺は「形状sからFを経由して動作aに至る経路」を表し、右辺は「形状sが、動作aを可能にする形状G(a)である度合い」を表す。この同型が、形状と動作の間の意味的対応関係を数学的に保証する。

### 2.2 随伴に伴う自然変換

随伴関手のペアには、2つの自然変換が伴う。

**Unit η: Id → G∘F** は、形状をFで動作に変換し、さらにGで形状に戻す合成写像 G(F(shape)) と、元の形状との間の関係を記述する。思考実験によって、この合成写像は元の形状の**機能的骨格（functional core）**を抽出する射影として機能することが確認された。たとえば、G(F(袋)) は袋の色、素材、ブランドロゴをすべて落とし、「開口部があり、内部空間があり、持ち手がある形状」という機能的本質だけを返す。

**Counit ε: F∘G → Id** は、動作をGで形状に変換し、さらにFで動作に戻す合成写像の性質を記述する。F(G(切る)) は「切る」だけでなく「削る」「刺す」といった関連動作の束を返す。すなわち、counitは**動作の意味的拡張**として機能する。

### 2.3 条件付き随伴：エージェントの介在

思考実験を通じて、本モデルにおける最も重要な発見がなされた。それは、**随伴は「裸の」ShapeとActionの間では成立しない**ということである。

たとえば、「袋で物を運ぶ」という場面を考える。「運ぶ」という動作が抽象的すぎると、G(運ぶ) が返す形状の集合は爆発する。平らな板でもバケツでも手のひらでも「運べる」からである。しかし、「最小労力で運ぶ」という条件を付けると、G(最小労力で運ぶ) は「開口部があり、持ち手があり、内部に物を収容できる形状」に収束し、G(F(袋)) が袋の機能的骨格に正しく戻る。

この発見は、随伴の成立条件そのものにエージェントの**目的・文脈・身体状態**（これらをまとめて**C**と呼ぶ）が組み込まれていることを意味する。形式的には、本モデルが扱うのは Shape と Action の間の随伴ではなく、**Shape と Action<sub>C</sub> の間のパラメータ付き随伴（parameterized adjunction）**である。

> **F<sub>C</sub> ⊣ G<sub>C</sub>**
>
> ここで C はエージェントの文脈（目的、制約、身体状態の複合体）

### 2.4 随伴の非対称性

この構造には本質的な非対称性がある。**Shape（形状）はエージェントの状態Cに依存しないが、Action（動作）はCに依存する。**

エージェントが疲れていようが急いでいようが、袋は袋のままであり、スイッチはスイッチのままである。形状は環境側の不変量である。一方、同じスーツケースに対して、元気なエージェントは「片手で持ち上げて運ぶ」を、右腕を怪我したエージェントは「左手で転がす」を選択する。Cが変わるとFの出力が変わる。

さらに、Gは形状を「生成」するのではなく、形状の「どの側面を見るか」を**選択**する。形状は複数の機能的側面を同時に内包する多面体構造を持っており、Gはエージェントの状態Cに応じて、その多面体のどの面に注目するかを決定する。たとえば、同じ袋に対して、疲れているエージェントは「持ち手」と「軽量性」に注目し、急いでいるエージェントは「容量」と「開口部の広さ」に注目する。

### 2.5 抽象度の保存

関手Gは、動作記述の抽象度を形状記述の粒度に**保存的に翻訳**する。

| 動作記述 | G が返す形状記述 | 抽象度 |
| :--- | :--- | :--- |
| 「指でスイッチの突起を0.5cm押し下げる」 | 「0.5cm可動する押しボタン機構」 | 低（具体的） |
| 「電灯をつける」 | 「制御可能な光源」 | 中 |
| 「部屋を明るくする」 | 「光を発する何か」 | 高（抽象的） |

これらは別々の出来事ではなく、同一の因果連鎖を異なる抽象度で記述したものである。Gは抽象度を変換するのではなく保存する。エージェントの状態Cが変わると、世界を切り取る抽象度λが変わり、その結果としてFとGの入出力の粒度が変わる。各抽象度λごとに独立した随伴 F<sub>λ</sub> ⊣ G<sub>λ</sub> が存在し、Cはどのλを選ぶかを決定する。

---

## 3. Coherence Signal：随伴を使う必然性

### 3.1 川床の思想

本モデルの設計思想は、**「川床（riverbed）」**という比喩に集約される。川床とは、水が流れる前にそこにある構造であり、水の流れ方を制約すると同時に、水の流れによって徐々に削られ変形していく。

この比喩をAIアーキテクチャに翻訳すると、エージェントは行動する前に、自身の内部構造の中で「ここは安定か不安定か」を検査できるべきだという要請になる。強化学習における報酬信号は本質的に事後的であり、行動して失敗して初めて「崩れていた」と分かる。川床の思想は、行動の前に安定性を内部的に検出する機構を要求する。

### 3.2 Coherence Signalの定義

この要請に応えるのが**coherence signal（整合性信号）**である。これは、随伴のunit ηの「大きさ」として定義される。

> **coherence signal = distance(shape, G(F(shape)))**

元の形状と、FとGを経由して再構成された形状との間の距離を測定する。この距離が小さければ、エージェントの現在の内部モデルは環境と整合しており（可換に近い）、距離が大きければ整合性が崩れている（非可換）。

重要なのは、**この信号は随伴構造がなければ定義できない**という点である。単なる双方向写像のペア（FとGが独立）では、G(F(x))を計算しても、それが「元に戻っているかどうか」を判定する基準がない。随伴のunit ηが存在するからこそ、「どれくらい戻っていないか」を測る自然な尺度が存在する。これが、本モデルにおいて随伴構造が装飾ではなく実質を持つ最も強い根拠の一つである。

### 3.3 Coherence Breakdownと創造性

可換性が崩れる瞬間——すなわちcoherence signalが急激に増大する瞬間——は、エージェントにとって**創造的問題解決が要求される瞬間**である。

たとえば、右腕を怪我した状態で、静かにしなければならない環境でスーツケースを運ぶ場面を考える。「引きずる」という通常の代替手段は騒音を生むため使えない。身体状態フィルターと文脈フィルターが干渉し、可換性が崩れる。このとき、エージェントは既存の動作プリミティブを新しい方法で合成し（たとえば「両膝で抱えて歩く」）、非可換性を解消しなければならない。

この構造は、**創造性を「可換図式の修復過程」として形式化する**可能性を示唆している。

### 3.4 Coherence Signalの位置づけの修正

ここで重要な修正を加える。当初の議論では、coherence signalがモデルの中心に据えられていた。しかし、より精密な分析の結果、coherence signalは**保留構造の5つの要件のうちの1つ（差異への感受性）を実装する手段**であり、モデル全体の中心ではないことが明らかになった（この点については第4節で詳述する）。

随伴を使う必然性は、coherence signalという一本の柱ではなく、保留構造の5要件のうち4つが随伴構造から自然に導出されるという、より広い基盤の上に立っている。

---

## 4. 保留構造：知性の最小構成要素

### 4.1 核としての保留構造

本モデルにおける最も独創的な概念は、**保留構造（suspension structure）**である。これは、複数の抽象度にまたがる随伴構造の束を貫く「核」として提案された。

従来の知性モデルでは、核となるものは固定された何か——身体モデル、最上位の目的、自己同一性——であった。しかし本モデルでは、核は**「まだ決まっていない」という構造そのもの**である。保留構造は特定の答えではなく、「問いを保持する装置」として機能する。

圏論における普遍的構造（極限、余極限）が、特定の対象ではなく「こういう性質を満たす唯一のもの」という条件として定義されるのと同様に、保留構造は「全ての抽象度を整合させる何か」という条件として定義され、状況に応じて具体化される。

> **知性とは、目的を明示的に保持することではなく、目的を忘れても破綻しない「保留構造＋記憶」を持つことである。**

### 4.2 保留構造の5つの要件

保留構造の最小構成要素として、以下の5つの要件が同定された。これらのうち1つでも欠ければ、知性は成立しない。

| 要件 | 内容 | 欠けた場合 |
| :--- | :--- | :--- |
| **志向性** | 何かに向かう指向性を持つこと | 方向のない反応機械になる |
| **差異への感受性** | 違いを検出できること | 環境変化に気づけない |
| **時間的持続** | 状態を一定期間保持できること | 瞬間的な反射に留まる |
| **自己と非自己の区別** | 自分の行動と環境の変化を区別できること | 自他の境界が消失する |
| **記憶** | 過去の経験を保持し参照できること | 学習が蓄積されない |

### 4.3 随伴構造との対応

これらの5要件は、本モデルのアーキテクチャにおいて以下のように実現される。

| 保留構造の要件 | アーキテクチャにおける所在 | 実現メカニズム |
| :--- | :--- | :--- |
| **差異への感受性** | 随伴構造（unit η） | coherence signal = distance(shape, G(F(shape))) |
| **志向性** | エージェント状態 C | Cに含まれる目標ベクトルが随伴のパラメータとして機能 |
| **時間的持続** | 動的ループ C(t) → C(t+1) | 状態が離散時間ステップで更新され、持続する |
| **自己と非自己の区別** | 随伴の非対称性 | ShapeはCに依存しない（環境＝非自己）、ActionはCに依存する（行動＝自己） |
| **記憶** | エージェント状態 C | Cの内部に記憶モジュールとして格納 |

注目すべきは、5要件のうち4つ（差異感受性・志向性・時間的持続・自己/非自己の区別）が随伴構造から自然に導出されるという点である。記憶のみが随伴の外側に位置するが、これはエージェント状態Cの内部に格納される。**記憶の内容は随伴が決め（何を記憶するか＝coherence signalが高かった経験）、記憶の保持はCが担う。**

---

## 5. 2層アーキテクチャ

### 5.1 設計原理

以上の分析から、本モデルのアーキテクチャは**2つの層**から構成される。

**随伴層（Adjoint Layer）**は、ShapeとActionの構造的関係を記述する。ここから差異への感受性と自己/非自己の区別が生まれる。この層の実装基盤として、動的グラフニューラルネットワーク（GNN）が想定される。ノードは機能プリミティブ（「握る」「包む」「支える」など）、エッジは合成可能性を表し、グラフのトポロジーとエッジ重みがcoherence signalに応じて変形し続ける。

**エージェント層（Agent Layer, C）**は、随伴層をパラメトライズする全内部状態を保持する。ここに志向性（目的）と記憶が格納される。Cは固定パラメータではなく、以下の更新則に従って動的に変化する状態変数である。

> **C(t+1) = update(C(t), action_result, coherence_signal)**

この2つの層が動的ループで結合されることで、時間的持続が実現される。エージェント層Cが随伴層の振る舞いを決定し、随伴層が世界と相互作用した結果（coherence signal）がエージェント層Cを更新する。これは川床の比喩そのものである——水の流れ（動作）が川床の形（グラフ構造）を削り、川床の形が水の流れを制約する。

### 5.2 動的GNNによる随伴層の実装構想

随伴層の実装基盤として、以下の構造を持つ動的GNNが構想される。

**静的な層**として、ノードは機能プリミティブを、エッジは合成可能性を表す。**随伴構造**として、F（Shape→Action）はグラフ上でのメッセージパッシングとして、G（Action→Shape）はグラフ全体のリードアウト（逆方向）として実装される。**変化し続ける部分**として、エッジの重み（合成のしやすさ）、ノードの活性化閾値、そしてグラフのトポロジー自体（新しいプリミティブの追加）が、coherence signalに応じて更新される。

### 5.3 言語野の拡張

本モデルの構造は、言語能力の追加を**同じ随伴パターンの階層化**として自然に実現する。

現在の構造が Shape ⇄ Action の随伴であるのに対し、拡張後は Shape ⇄ Action ⇄ Language という2つの随伴の連鎖となる。言語は、形状と動作の随伴に「名前をつける」もう一つの随伴層である。この拡張において、新しい原理の導入は不要であり、同じ随伴＋coherenceのパターンが層ごとに繰り返されるだけである。

---

## 6. Active Inferenceとの対応関係

### 6.1 構造的対応

本モデルとカール・フリストンが提唱するActive Inference（能動的推論）の間には、強い構造的対応が存在する [1]。

| 本モデルの概念 | Active Inferenceの概念 |
| :--- | :--- |
| Coherence signal (η) | 自由エネルギー（予測誤差） |
| F⊣Gの動的ループ | Action-Perception loop |
| エージェント状態 C | 生成モデルのパラメータ |
| Coherence breakdown | サプライズ（予測外の観測） |

特に、coherence signal ≈ 自由エネルギーという対応は本質的である。G(F(shape))は「エージェントが現在の内部状態Cと形状shapeから予測する世界のあり方」であり、distance(shape, G(F(shape)))はその予測と現実の乖離、すなわち予測誤差に他ならない。

### 6.2 本モデルの独自性

しかし、本モデルはActive Inferenceの単なる再定式化ではない。以下の概念はActive Inferenceの枠組みでは直接扱えない。

**保留構造**は、Active Inferenceにおける「生成モデル」とは質的に異なる。生成モデルは世界の確率的な記述であるのに対し、保留構造は「まだ決まっていない」という未確定性そのものを構造化したものである。

**Coherence breakdownが創造性を生む**という主張は、Active Inferenceにおけるサプライズ最小化の原理とは方向性が異なる。Active Inferenceではサプライズ（予測誤差）は最小化すべきものであるが、本モデルではcoherence breakdownは創造的問題解決の契機として積極的に位置づけられる。

**随伴の非対称性**——ShapeはCに依存しないがActionはCに依存する——は、Active Inferenceの対称的な枠組みでは明示的に扱われていない。

### 6.3 位置づけ

本モデルは、**「圏論という代数的な言語でActive Inferenceを再定式化し、さらに保留構造と創造性の概念で拡張したもの」**として位置づけることができる。Active Inferenceがベイズ確率論を基盤とするのに対し、本モデルは随伴関手という構造そのものに焦点を当てる。これにより、確率的な定式化が難しい概念——保留、未確定性、創造性——をより直接的に扱える可能性がある。

なお、Smithe (2024) による**Structured Active Inference** [2] は、圏論的システム理論を用いてActive Inferenceを大幅に一般化した研究であり、本モデルの最も近い先行研究である。特に、「エージェントの状態によって利用可能な行動が変わる」というmode-dependenceの概念は、本モデルにおけるパラメータ付き随伴のCに直接対応する。

---

## 7. 実装への展望

### 7.1 技術要素の対応表

| 理論コンポーネント | 実装方針 | ツール・先行研究 |
| :--- | :--- | :--- |
| Shape圏 | 3Dオブジェクトの点群またはメッシュ | ShapeNet [3], PartNet |
| Action圏 | 身体部位とオブジェクト表面点の関係性の確率分布 | ZSP3A [4], Contact-GraspNet [5] |
| 関手 F | GNNによるアフォーダンス予測 | PyTorch Geometric [6] |
| 関手 G | GNNによる逆推論 | 新規開発 |
| Coherence signal | 再構成誤差 distance(shape, G(F(shape))) | 自己教師あり学習 |
| エージェント状態 C | RNNまたはTransformerの潜在状態 + 外部メモリ | Neural Turing Machine [7] |

### 7.2 最小限の検証タスク

理論の最初の実証として、以下の最小限の実験を提案する。

第一に、ShapeNetから特定のカテゴリ（椅子、カップなど）の3Dモデルを選び、形状と把持姿勢のペアデータを作成する。第二に、PyTorch Geometricを用いてGNNベースのFとGを実装する。第三に、loss = distance(shape\_contact\_region, G(F(shape))) を損失関数として、FとGを同時に訓練する。

この実験が成功すれば、「随伴構造が、再構成誤差を最小化する形で、形状と行動の間の双方向推論を学習できる」ことの最初の実証となる。

---

## 8. 結論と今後の課題

本研究ノートでは、物理的意味的随伴モデルの理論的枠組みを、思考実験による検証と段階的な精緻化を通じて構築した。主要な成果を以下にまとめる。

**理論的成果**として、随伴構造がエージェントの文脈Cによってパラメトライズされる「条件付き随伴」の発見、coherence signalによる内部安定性検出機構の定式化、保留構造の5要件の同定とそのうち4つが随伴構造から自然に導出されることの確認、そしてcoherence breakdownを創造性の発生条件として位置づける枠組みの提示がある。

**先行研究との関係**として、Active Inferenceとの強い構造的対応が確認されると同時に、保留構造・創造性・随伴の非対称性という独自の貢献が明確化された。

**今後の課題**として、以下が挙げられる。第一に、随伴のunit ηの性質（自然変換としての可換性など）が本モデルにおいて形式的に満たされているかの厳密な検証。第二に、保留構造の「具体化される瞬間」の条件の精密な定式化。第三に、動的GNNのグラフ変形の時間スケールの設計。第四に、言語層の追加と既存のLLMとの関係の明確化。第五に、最小限の検証タスクの実行による理論の実証。

本モデルは、「データから学習する」AIから「身体を通して世界を再定義する」AIへの転換を目指すものである。その射程は、AIアーキテクチャの設計に留まらず、知性そのものの再定義にまで及ぶ可能性がある。

---

## 参考文献

[1]: Parr, T., Pezzulo, G., & Friston, K. J. (2022). *Active Inference: The Free Energy Principle in Mind, Brain, and Behavior*. MIT Press.

[2]: Smithe, T. S. C. (2024). *Structured Active Inference (Chapters 1-3)*. arXiv:2406.07577.

[3]: Chang, A. X., et al. (2015). *ShapeNet: An Information-Rich 3D Model Repository*. arXiv:1512.03012.

[4]: Kim, H., et al. (2024). *Zero-Shot Learning for the Primitives of 3D Affordance in General Objects*. arXiv:2401.12978.

[5]: Sundermeyer, M., et al. (2021). *Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered Scenes*. arXiv:2103.14243.

[6]: Fey, M., & Lenssen, J. E. (2019). *Fast Graph Representation Learning with PyTorch Geometric*. arXiv:1903.02428.

[7]: Graves, A., et al. (2014). *Neural Turing Machines*. arXiv:1410.5401.

[8]: Gavranović, B., et al. (2024). *Categorical Deep Learning: An Algebraic Theory of Architectures*. ICML 2024. arXiv:2402.15332.
