# 議論ログ（2026年2月13日）

## 概要

本日の議論は、Agent C v2の志向性実験の結果解釈から始まり、OnlineLearnerとAgent Cの役割の競合、目的空間Pの再導入、言語と随伴の関係、そして「価値判断の枠組み」の設計思想に至る、理論の根幹に関わる深い展開となった。

---

## 1. 実験結果の解釈：「この設計だからこうなる」

### 背景

Agent C v2をConditionalAdjunctionModelに統合し、OnlineLearnerを無効化した状態で志向性実験を実施した。結果は以下の通り。

| 指標 | Cube (Known) | Torus (Novel) | Ratio |
|:---|---:|---:|---:|
| Coherence Signal | 0.1151 | 0.4944 | 4.29x |
| Attention (‖Δh‖) | 1.1784 | 1.1950 | 1.01x |
| Priority (mean) | 18.3212 | 3.0314 | 0.17x |
| Uncertainty | 34.0559 | 34.1487 | 1.00x |
| KL Divergence | 0.0426 | 0.0625 | 1.47x |

### keisuke氏の指摘：数値の「意味」を読む

当初、Attention比率1.01xは「悪化」、Priority逆転0.17xは「バグ」と解釈されていた。keisuke氏はこれを以下のように読み替えた。

**Attention 1.01x = 飽和の正しい表現**: Agent Cは同じCubeとTorusを10回繰り返し見ている。同じものに慣れ、予測通りの入力に対して内部状態を大きく変える理由がない。これは志向性の欠如ではなく、退屈の表現である。

**Priority逆転 0.17x = 「前の経験が次の構えを決める」**: coherence_spatial_prevが前の形状の値を引き継ぐため、Torus直後のCubeでは「さっき大きな破綻があった、今度こそ注意しよう」と高いPriorityを持ち、Cube直後のTorusでは「さっきは問題なかった、油断」と低いPriorityを持つ。これは原始的な志向性である。

**KL 1.47x = 新規性を感じている**: Agent Cは新規形状に対して信念をより大きく修正している。微弱だが正しい方向。

### 教訓

実験結果を「性能指標の向上/悪化」で判断するのではなく、「この設計だからこうなる」という視点で読むべきである。すべてのシグナルが微弱であることは、設計の問題ではなく、訓練がこの設計を活かしていないことを示している。

---

## 2. OnlineLearnerとAgent Cの競合

### 根本的な問題

3つの問題（KL=0、Torusの新規性消失、Priority差の消失）は互いに関連しており、根本原因は1つである。

Conditional Adjunction（F_C ⊣ G_C）では、Cが唯一のパラメータであるべきである。しかし、OnlineLearnerがF/Gの重みを直接更新すると、Agent Cの役割を奪う。川の水流（OnlineLearner）が川床（F/G）を直接削っているが、地質（Agent C）が関与していない状態。

### 解決策

OnlineLearnerを無効化し、Agent Cの内部状態変化のみでF/Gの適応が起きるようにした。これにより、KL > 0、Coherence持続（4.29x）が実現された。

### 新たに露呈した問題

FiLMのConditioningが弱い。Agent Cの内部状態は変化しているが、contextを経由してF/Gの出力を有意に変えるほどの影響力を持っていない。これは訓練時にAgent Cのcontextがほぼ一定（1ステップのみ）で、逐次的な経験を積んでいないため、FiLMが「飾り」になっている。

---

## 3. 目的空間Pの再浮上

### 言語は随伴の要件を満たさない

research_note_ja.mdのセクション5.5では、言語を「同じ随伴パターンの階層化」として扱う構想が記述されていた。しかし、keisuke氏から以下の指摘があった。

**言語は随伴の要件を満たさない可能性がある。** 随伴（F ⊣ G）は双方向の変換を要求するが、「椅子」という言葉から特定の形状を一意に復元できない（多対多の写像）。さらに、人間は「思考だけの中で言葉を選ぶことができる」。言語は身体から切り離されて操作可能であり、身体に縛られたF ⊣ Gとは質的に異なる。

### 目的空間Pの必要性

2月12日の議論で不採用とされた「目的空間P」が、言語接地のために必要である可能性が浮上した。ただし、不採用の理由であった「目的を外部から注入することは余白を埋める行為」という原則は維持される。

### 3層構造の提案

| 層 | 内容 | 身体との関係 |
|:---|:---|:---|
| Layer 1: 身体的随伴（F ⊣ G） | 形状⇄アフォーダンス | 身体に縛られている |
| Layer 2: 目的空間（P） | 経験から抽出された「何をしたいか」の表現 | 身体から部分的に切り離されている |
| Layer 3: 言語（L） | Pの構造に名前をつけたもの | 身体なしでも操作可能 |

言語は、形状やアフォーダンスと直接随伴するのではなく、目的空間Pを経由して接地される。「椅子」という言葉は特定の形状ではなく、「座る」という目的と結びつく。

---

## 4. 「良いものを良いと感じる力」：価値判断の枠組み

### 核心的な洞察

keisuke氏の「良いものを良いと感じる力」という言葉から、目的空間Pの設計思想が明確になった。

**Pは「完全に創発」でもなく、「完全に設計」でもない。** 人間の赤ちゃんも、生まれたときから「快/不快」「安全/危険」といった原始的な価値判断の枠組みは持っている（遺伝的に与えられたもの）。しかし、「何が快か」「何が安全か」の具体的な内容は、経験から学ぶ。

| 設計するもの | 創発するもの |
|:---|:---|
| 価値判断の**軸**（coherence, uncertainty, priority） | その軸の上で**何が良いか**の具体的判断 |
| 「破綻＝注意すべき」という枠組み | 「どの程度の破綻なら許容できるか」 |
| 「不確実＝探索すべき」という枠組み | 「どの種類の不確実性が重要か」 |

### 今日の実験結果との対応

Priority逆転（0.17x）で見えた「前の経験が次の構えを決める」というのは、目的空間Pの萌芽である。Agent Cは、coherenceという設計された軸を使って、「破綻を避けようとする構え」という経験から学んだ判断を行っている。この「構え」が蓄積され、抽象化されていくと、目的空間Pになる。

### 余白が先にある

目的空間Pの正しい理解は以下の通り。

1. 保留（余白）が先にある。Agent Cの内部状態は、最初は未分化。
2. 外部からの刺激（形状を見る、coherenceを感じる）を受け取る。
3. 余白が刺激に応じて変化する。
4. 繰り返しの経験の中で、潜在状態の中に構造が創発する。
5. その構造がP。設計したのではなく、創発した構造が目的空間。

Pに直接何かを書き込むことは技術的には可能だが、それは余白を埋める行為。言語入力は「Pを書き換える命令」ではなく、「Pを揺さぶる刺激」として扱うべきである。

ただし、Pの枠組み（価値判断の軸）は設計する。「良いものを良いと感じる力」とは、この枠組みを持ちながら、具体的な判断は自分で下すということ。

---

## 5. 理論への影響と次のステップ

### research_note_ja.mdへの影響

セクション3.5（抽象度の保存）の以下の記述を修正する必要がある。

> 「目的の階層はGNNの活性化パターンの粒度の階層として自然に表現される。別途「目的空間」を設計する必要はない。」

今日の議論により、目的空間Pは必要であると結論された。ただし、それは「外部から目的を注入する空間」ではなく、「Agent Cの内部状態の中で経験から創発する構造」として再定義される。

### セクション5.5（言語野の拡張）への影響

> 「Shape ⇄ Action ⇄ Language という2つの随伴の連鎖」

言語は随伴の要件を満たさない可能性がある。言語接地は、随伴の階層化ではなく、目的空間Pを経由した3層構造として再設計する必要がある。

### 次のステップ

1. **research_note_ja.mdの改訂**: セクション3.5と5.5を今日の議論に基づいて修正
2. **目的空間Pの形式化**: Agent Cの内部状態の中でPがどう創発するかの理論的記述
3. **訓練方法の根本的見直し**: Agent Cが逐次的な経験の中でF/Gを調整する訓練ループの設計
4. **言語接地の再設計**: 随伴ではなく、Pを経由した3層構造の設計

---

## 6. AIの常識が通じない部分

今日の議論を通じて、このモデルでは通常のAI開発の常識が通用しない点が明確になった。

**「訓練エポック数を増やせば改善する」は通用しない。** 何を最適化しているのかが問題。Coherenceを下げることが目的ではない。

**「損失関数を工夫すれば性能が上がる」は通用しない。** 保留構造は「タスク達成」とは独立した性質。タスクを完璧に解けるようになることは、保留構造の消失を意味するかもしれない。

**「性能指標の向上＝成功」は通用しない。** Attention比率の低下は「退屈」の正しい表現であり、Priority逆転は「原始的な志向性」である。

**「モデルを大きくすればスケールする」は通用しない。** スケールの問題は「モデルの大きさ」ではなく、「世界との結合の強さ」（身体の獲得）で解決される可能性がある。

このモデルを正しく理解し開発するためには、「パターンマッチング」ではなく、「モデルの立場に立って経験を想像する」という思考が必要である。
