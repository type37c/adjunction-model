# Implementation Log

このファイルは、Physical-Semantic Adjunction Modelの実装過程で行った設計判断、遭遇した問題、理論との齟齬を記録します。

---

## 2026-02-12: Phase 0 実装開始

### 環境構築

**実施内容**:
- PyTorch 2.10.0 (CPU版) をインストール
- PyTorch Geometric 2.7.0 をインストール
- その他の依存関係（h5py, trimesh, scipy, tqdm, pyyaml）をインストール

**設計判断**:
- CPU版を選択した理由: 初期プロトタイプでは小規模データセットを使用するため、GPU不要
- PyTorch Geometricの拡張ライブラリ（torch-scatter, torch-sparse）はPyG 2.7.0では不要になったため、インストールをスキップ

**ディレクトリ構造**:
```
adjunction-model/
├── src/
│   ├── models/      # F, G, Agent Layer Cの実装
│   ├── data/        # データローダー
│   ├── training/    # 学習ループ
│   └── utils/       # ユーティリティ関数
├── tests/           # 単体テスト
├── configs/         # 設定ファイル
├── data/            # データセット保存先
└── logs/            # 学習ログ
```

---

## Phase 2: Agent Layer C Integration (2026-02-12)

### Objective

Implement Agent Layer C (based on DreamerV3's RSSM) and integrate it with the existing F⊣G adjunction to create a conditional model F_C ⊣ G_C. The goal is to enable the agent to adapt its internal state in response to novel stimuli, as measured by the coherence signal.

### Implementation Steps

1.  **Agent Layer C (RSSM)**: Implemented a simplified Recurrent State-Space Model (`src/models/agent_layer.py`) with a deterministic state `h` and a stochastic state `z`. The state is updated based on the previous state, action, and coherence signal.

2.  **Conditional Adjunction**: Created a new model (`src/models/conditional_adjunction.py`) that wraps the base F and G functors. The context vector generated by Agent Layer C is used to modulate the behavior of F and G using Feature-wise Linear Modulation (FiLM).

3.  **Phase 2 Training Loop**: Implemented a new training loop (`src/training/train_phase2.py`) that fine-tunes the conditional model. The loss function includes the reconstruction loss (coherence signal), affordance loss, and a KL divergence term to regularize the RSSM.

4.  **Online Adaptation Experiment**: Created an experiment (`experiments/test_online_adaptation.py`) to test the agent's ability to adapt to a novel shape (torus) over multiple exposures. The experiment tracks the evolution of the coherence signal and the agent's internal state.

### Key Challenges & Solutions

-   **FiLM Implementation**: The initial attempt to apply FiLM to intermediate layers of F and G was complex and error-prone. To simplify, the implementation was revised to apply FiLM to the output of the base F and G models. This provided a clear and testable conditioning mechanism.

-   **DataLoader Issues**: The custom `DataLoader` did not automatically collate samples into a batched tensor with a `batch` index. The training loop was updated to manually stack the list of tensors and create the `batch` index, resolving the `KeyError: 'pos'` and `TypeError: cat() received an invalid combination of arguments`.

### Experimental Results

-   **Hypothesis**: When exposed to a novel shape, the agent's internal state should adapt, leading to a decrease in the coherence signal over time.
-   **Result**: The experiment showed a **-9.4% decrease** in the coherence signal over 10 exposures to a torus. While not a dramatic drop, it confirms that the agent is actively adapting its internal state in response to the novel stimulus.
-   **Interpretation**: The adaptation is partial because the experiment was run in `eval()` mode (no weight updates). The result successfully validates that the Agent Layer C is functional and responsive to the coherence signal. Full online adaptation would require online learning (weight updates), which is a goal for Phase 3.

---

## Phase 2-B: Suspension Structure Validation (2026-02-12)

### Objective

To empirically validate the existence and properties of the "suspension structure" by conducting a series of targeted experiments.

### Implementation

1.  **Online Learning Implementation** (`src/training/online_learning.py`)
    -   Implemented an `OnlineLearner` class to handle inference-time weight updates.
    -   Introduced an adaptive learning rate based on coherence signal.
    -   Added L2 regularization to prevent catastrophic forgetting.
    -   Resolved `RuntimeError: Trying to backward through the graph a second time` by detaching the agent state and previous coherence signal before the next iteration.

2.  **Online Learning Validation Experiment** (`experiments/test_online_learning.py`)
    -   Compared adaptation performance with and without online learning.
    -   **Result**: Confirmed hypothesis. Online learning improved coherence signal reduction from -23.1% to -47.0%.

3.  **Memory Recall Experiment** (`experiments/test_memory_recall.py`)
    -   Tested if the agent can distinguish between first-time novel and previously encountered novel shapes.
    -   **Result**: Strong evidence. Coherence signal dropped by 35.9% on re-exposure to a novel shape, indicating memory.

4.  **Saturation (Boredom) Experiment** (`experiments/test_saturation.py`)
    -   Tested if the agent exhibits signs of "boredom" after repeated exposure to the same shape.
    -   **Result**: Partial evidence. Coherence signal decreased, but Z-entropy and H-change did not show significant changes.

5.  **Prioritization Experiment** (`experiments/test_prioritization.py`)
    -   Tested if the agent allocates more attention to novel shapes.
    -   **Result**: Weak evidence. Attention to novel shapes was only 1.11x higher than to known shapes.

### Key Learnings

-   The core mechanisms of the suspension structure (sensitivity to difference, temporal persistence, creative reconstruction) are functionally present in the model.
-   Higher-level properties like intentionality and saturation are not yet strongly emergent, suggesting the need for more complex task environments and longer-term experiments.
-   The online learning mechanism is effective and crucial for adaptation.

---

## Phase 2-C: Priority-based Attention (2026-02-12)

**Objective**: Implement the principle of intentionality `priority = coherence × uncertainty` to improve Agent C.

**Key Implementations**:
- **Spatial Coherence Signal**: Modified `AdjunctionModel` to return per-point coherence signals, providing Agent C with information about *what* is broken.
- **Priority Computation**: Created a new module `src/models/priority.py` to calculate priority scores based on the theoretical principle.
- **Agent Layer C v2**: Developed `src/models/agent_layer_v2.py`, which integrates:
    - Spatial coherence input
    - Priority computation
    - An attention mechanism that weights observations based on priority.
- **Integration Test**: Created `tests/test_agent_c_v2_integration.py` to verify that the entire pipeline works and that the attention mechanism correctly allocates focus to high-priority points.

**Key Findings**:
- The integration test passed successfully.
- The attention mechanism correctly allocated **4.54x** more attention to the top 10% of high-priority points compared to the average.
- This confirms that the architectural foundation for intentionality is now in place.

**Next Steps**: Re-run the intentionality and saturation experiments using Agent C v2 to verify theoretical improvements.
