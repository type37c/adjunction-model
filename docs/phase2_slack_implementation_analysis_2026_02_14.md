# Phase 2 Slack実装の分析と教訓 - 2026年2月14日

## 概要

本ドキュメントは、Phase 2 Slack実験（η/ε余白保存実験）の実装過程で発生した一連の問題と、その解決を通じて得られた理論的・実装上の重要な知見をまとめるものである。

当初の単純なバグ修正という見立ては誤りであり、実際には**モデルのインターフェース設計、テスト手法、そして訓練プロセスの根本的な設計思想**にまで及ぶ、複数の根深い問題が明らかになった。

## 発見された問題の分類と分析

問題は大きく4つのカテゴリに分類できる。

### 1. データ形式の不一致（設計の甘さ）

最も頻発したエラーは、モジュール間で受け渡されるデータの形式が統一されていなかったことに起因する。

- **問題点**: Functor F/Gはグラフ形式 `(N, dim)`（N: バッチ全体の総ポイント数）を期待する設計であったが、データローダーや他のモジュールはバッチ形式 `(B, num_points, dim)`（B: バッチサイズ）を生成していた。これにより、各モジュールの境界で形状の不整合が多発した。
- **具体例**:
    - `affordances_pred` `(N, 5)` vs `affordances_gt` `(B, 512, 5)`
    - `reconstructed` `(B, 512, 3)` vs Functor Fの期待入力 `(N, 3)`
- **原因**: モデル間のインターフェース仕様、特にテンソル形状に関する規約が明確に定義されておらず、各実装者の暗黙の前提に依存していた。

### 2. テンソル次元の不整合（実装の甘さ）

データ形式の不一致と関連して、テンソルの次元（ランク）に関する問題も発生した。

- **問題点**: RSSM（`agent_layer.py`）は、`coherence_signal`を2次元テンソル `(B, 1)` として期待していたが、実際には1次元 `(B,)` で渡されていた。これにより、`torch.cat`操作で次元ミスマッチエラーが発生した。
- **原因**: 実装時に次元数を常に意識し、必要に応じて `unsqueeze` や `squeeze` を行う習慣が徹底されていなかった。特に、スカラー値をバッチで扱う際に注意が不足していた。

### 3. 統合テストの欠如（検証の甘さ）

個別のモジュールは単体テストをパスしていた可能性があるが、それらを結合したエンドツーエンドのテストが不足していた。

- **問題点**: Phase 2 Slack実験のトレーナースクリプトを初めて実行した段階で、上記の問題が連鎖的に発覚した。これは、開発サイクルの最終段階まで統合上の問題が発見されなかったことを意味する。
- **原因**: ユニットテストだけでなく、モデル全体を動かす統合テストの重要性が軽視されていた。特に、PyTorchのようなフレームワークでは、forward passが一度でも通ることを確認する簡単なテストが、多くの形状問題を早期に発見する上で極めて有効である。

### 4. 訓練プロセスの根本的な設計不備（理論と実装の乖離）

今回発見された中で最も深刻かつ重要な問題である。これは単なる実装ミスではなく、**プロジェクトの核心的目標である「保留構造の創発」を達成するための理論と、実際の訓練プロセスが完全に矛盾していた**ことを示している。

- **理論的目標**: 随伴性 `F ⊣ G` におけるunit `η` とcounit `ε` を誤差として最小化するのではなく、「余白（slack）」として保存する。この「余白」が、エージェントが能動的に世界と関わるための自由度となり、保留構造が創発する基盤となる。

- **実装上の矛盾**:
    1. **Phase 1 (Pre-training)**: F⊣Gを**再構成損失（L_recon）**で事前学習していた。これは `η = ||Shape - G(F(Shape))||` を直接最小化する行為であり、**理論的目標とは真逆**のアプローチである。これにより、最も重要な「余白」が意図的に潰されていた。
    2. **Phase 3 (Agent-only Training)**: F/Gの重みを凍結し、Agent Cのみを学習していた。F/Gが固定されているため、ηもεも構造的に変化できず、当然「余白」のダイナミクスは生まれない。
    3. **Phase 2の欠如**: F⊣GとAgent Cを**同時に**、かつ**再構成損失なしで**学習するという、理論を実現する上で不可欠な「Phase 2」が実装されていなかった。

- **結論**: これまでの訓練プロセスでは、保留構造が創発する可能性は構造的に排除されていた。エージェントのポリシー設計以前に、そのポリシーが機能するための環境（F⊣Gの性質）が整っていなかった。

## 解決策と新たな設計方針

上記の問題に対し、以下の修正を実施した。

1. **データ形式の統一**: `collate_fn`をデータローダーに導入し、全てのデータをグラフ形式に統一。また、forward passの各所で形状変換（`reshape`, `repeat_interleave`）を明示的に行い、インターフェースを整合させた。

2. **次元の保証**: `coherence_signal`など、スカラー的な値を扱う箇所で `unsqueeze` を行い、次元数を保証するコードを追加した。

3. **Phase 2 Slack実験の実装**: 今回のデバッグを経て完成した `train_phase2_slack.py` は、**理論的に正しい訓練プロセスを実装した初の試み**となる。
    - **F⊣Gをゼロから学習**: 事前学習された重みを使わず、ランダム初期化から学習を開始する。
    - **再構成損失の排除**: `L_recon` を損失関数から完全に削除。
    - **アフォーダンス損失による学習**: `L_aff` のみをF⊣Gの勾配計算に使用する。
    - **Coherence正則化**: ηが0に収束することを防ぐため、`L_coherence` を導入（ただし、これは最小化ではなく、一定値を保つための項）。

## 教訓と今後の展望

- **インターフェース仕様の文書化**: モデル間のテンソル形状、データ型、形式（グラフ/バッチ）を定義した仕様書を作成し、遵守する必要がある。
- **早期の統合テスト**: 新機能実装後は、まずダミーデータでモデル全体のforward passが通ることを確認するテストを義務付ける。
- **理論と実装の同期**: 理論的なアイデアを実装に落とし込む際は、その核心的な要件が訓練プロセスや損失関数に正しく反映されているか、繰り返しレビューする必要がある。

今回の修正により、我々は初めて「保留構造の創発」を観測できる可能性のある実験環境を手に入れた。今後の小規模実験および大規模実験を通じて、ηとεが「余白」として機能し、エージェントの行動に変化が生まれるかを注視していく。
