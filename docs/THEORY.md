# 物理的意味的随伴モデル：知性の本質としての保留構造
Research Note — Final Draft v2.0

## 1. 導入：現在のAIに欠けているものと、知性の本質への問い
現在の大規模言語モデル（LLM）は、膨大なテキストデータから単語間の統計的共起関係を学習することで、人間に匹敵する自然言語処理能力を獲得した。しかし、この能力には根本的な限界がある。LLMは「袋」という単語と「運ぶ」という単語の確率的な結びつきを知っているが、重力に逆らって物を持ち上げる労力や、袋が破れそうなときの指先の感覚を知らない。つまり、身体性（embodiment）の欠如と、それに伴う**記号接地問題（symbol grounding problem）**が未解決のまま残されている [1]。

この問題は、未知の状況への対応において致命的となる。現在のAIは、学習データに含まれないオブジェクトに遭遇したとき、そのオブジェクトが何に使えるか——すなわちアフォーダンス（affordance）——を直感的に推論することができない。過去のデータを検索・模倣することしかできず、新しい意味を生成する能力を持たない。

本研究ノートは、この問題に対する新しいアプローチとして**「物理的意味的随伴モデル（Physical-Semantic Adjunction Model）」**を提案する。このモデルの核心は、知性の本質が「未確定性を保持し、新しい意味を創発する能力」にあるという問いから出発する。知性とは、単に安定した理解を維持するだけでなく、その理解が破綻したときに、その「壊れた状態」を保持し、新しい理解を再構成しようとするダイナミクスそのものにあると考える。

このダイナミクスを形式化するために、圏論における**随伴（adjunction）という数学的構造と、本モデルで提唱する保留構造（suspension structure）**を統合したアーキテクチャを構築する。これは、形状（Shape）と動作（Action）の間の双方向的な意味関係を、エージェントの身体性を通じてリアルタイムに構成し、記号接地問題の解決と創造性の創発を目指すものである。

## 2. 保留構造：知性の最小構成要素としての「懸垂（Suspension）」
本モデルにおける最も独創的な概念は、**保留構造（suspension structure）**である。これは、複数の抽象度にまたがる随伴構造の束を貫く「核」として提案された。知性の本体は、この保留構造のダイナミクスそのものにある。

### 2.1 核としての「まだ決まっていない」という構造
従来の知性モデルでは、核となるものは固定された何か——身体モデル、最上位の目的、自己同一性——であった。しかし本モデルでは、核は**「まだ決まっていない」という構造そのもの**である。保留構造は特定の答えではなく、「問いを保持する装置」として機能する。

圏論における普遍的構造（極限、余極限）が、特定の対象ではなく「こういう性質を満たす唯一のもの」という条件として定義されるのと同様に、保留構造は「全ての抽象度を整合させる何か」という条件として定義され、状況に応じて具体化される。

知性とは、目的を明示的に保持することではなく、目的を忘れても破綻しない「保留構造＋記憶」を持つことである。

### 2.2 保留構造の5つの要件
保留構造の最小構成要素として、以下の5つの要件が同定された。これらのうち1つでも欠ければ、知性は成立しない。

|要件           |内容                 |欠けた場合       |
|:------------|:------------------|:-----------|
|**志向性**      |何かに向かう指向性を持つこと     |方向のない反応機械になる|
|**差異への感受性**  |違いを検出できること         |環境変化に気づけない  |
|**時間的持続**    |状態を一定期間保持できること     |瞬間的な反射に留まる  |
|**自己と非自己の区別**|自分の行動と環境の変化を区別できること|自他の境界が消失する  |
|**記憶**       |過去の経験を保持し参照できること   |学習が蓄積されない   |

## 3.5 抽象度の保存
関手Gは、動作記述の抽象度を形状記述の粒度に保存的に翻訳する。

|動作記述                  |G が返す形状記述         |抽象度   |
|:---------------------|:-----------------|:-----|
|「指でスイッチの突起を0.5cm押し下げる」|「0.5cm可動する押しボタン機構」|低（具体的）|
|「電灯をつける」              |「制御可能な光源」         |中     |
|「部屋を明るくする」            |「光を発する何か」         |高（抽象的）|

これらは別々の出来事ではなく、同一の因果連鎖を異なる抽象度で記述したものである。Gは抽象度を変換するのではなく保存する。エージェントの状態Cが変わると、世界を切り取る抽象度λが変わり、その結果としてFとGの入出力の粒度が変わる。各抽象度λごとに独立した随伴 F<sub>λ</sub> ⊣ G<sub>λ</sub> が存在し、Cはどのλを選ぶかを決定する。

## 4. Coherence Signal：保留構造を起動させる「トリガー」
Coherence signalは、随伴構造が安定した状態にあるか、それとも破綻しているかを測る内部指標であり、知性の本体である保留構造を起動させるトリガーとして機能する。

### 4.1 川床の思想
本モデルの設計思想は、**「川床（riverbed）」**という比喩に集約される。川床とは、水が流れる前にそこにある構造であり、水の流れ方を制約すると同時に、水の流れによって徐々に削られ変形していく。

この比喩をAIアーキテクチャに翻訳すると、エージェントは行動する前に、自身の内部構造の中で「ここは安定か不安定か」を検査できるべきだという要請になる。強化学習における報酬信号は本質的に事後的であり、行動して失敗して初めて「崩れていた」と分かる。川床の思想は、行動の前に安定性を内部的に検出する機構を要求する。

### 4.2 Coherence Signalの定義
この要請に応えるのが**coherence signal（整合性信号）**である。これは、随伴のunit ηの「大きさ」として定義される。

`coherence signal = distance(shape, G(F(shape)))`

元の形状と、FとGを経由して再構成された形状との間の距離を測定する。この距離が小さければ、エージェントの現在の内部モデルは環境と整合しており（可換に近い）、距離が大きければ整合性が崩れている（非可換）。

重要なのは、この信号は随伴構造がなければ定義できないという点である。単なる双方向写像のペア（FとGが独立）では、G(F(x))を計算しても、それが「元に戻っているかどうか」を判定する基準がない。随伴のunit ηが存在するからこそ、「どれくらい戻っていないか」を測る自然な尺度が存在する。これが、本モデルにおいて随伴構造が装飾ではなく実質を持つ最も強い根拠の一つである。

### 4.3 Coherence Breakdownと創造性
可換性が崩れる瞬間——すなわちcoherence signalが急激に増大する瞬間——は、エージェントにとって創造的問題解決が要求される瞬間である。このcoherence breakdownが、知性の本体である保留構造を起動させるトリガーとなる。

たとえば、右腕を怪我した状態で、静かにしなければならない環境でスーツケースを運ぶ場面を考える。「引きずる」という通常の代替手段は騒音を生むため使えない。身体状態フィルターと文脈フィルターが干渉し、可換性が崩れる。このとき、エージェントは既存の動作プリミティブを新しい方法で合成し（たとえば「両膝で抱えて歩く」）、非可換性を解消しなければならない。

この構造は、創造性を「可換図式の修復過程」として形式化する可能性を示唆している。

## 5. 2層アーキテクチャ：保留構造を実装する器
以上の分析から、本モデルのアーキテクチャは2つの層から構成される。この2層構造が、知性の本体である保留構造を実装する器となる。

### 5.1 設計原理
**随伴層（Adjoint Layer）**は、ShapeとActionの構造的関係を記述する。ここから差異への感受性と自己/非自己の区別が生まれる。この層は、保留構造が「平時」に参照する安定した理解の状態を提供する。

**エージェント層（Agent Layer, C）**は、随伴層をパラメトライズする全内部状態を保持する。ここに志向性（目的）と記憶が格納される。Cは固定パラメータではなく、以下の更新則に従って動的に変化する状態変数である。このエージェント層こそが、保留構造のダイナミクスを担う中核である。

`C(t+1) = update(C(t), action_result, coherence_signal)`

この2つの層が動的ループで結合されることで、時間的持続が実現される。エージェント層Cが随伴層の振る舞いを決定し、随伴層が世界と相互作用した結果（coherence signal）がエージェント層Cを更新する。これは川床の比喩そのものである——水の流れ（動作）が川床の形（グラフ構造）を削り、川床の形が水の流れを制約する。

### 5.2 保留構造の5つの要件とアーキテクチャの対応
保留構造の5要件は、本モデルのアーキテクチャにおいて以下のように実現される。

|保留構造の要件      |アーキテクチャにおける所在      |実現メカニズム                                        |
|:------------|:------------------|:----------------------------------------------|
|**差異への感受性**  |随伴層（unit η）        |coherence signal = distance(shape, G(F(shape)))|
|**志向性**      |エージェント状態 C         |Cに含まれる目標ベクトルが随伴のパラメータとして機能                     |
|**時間的持続**    |動的ループ C(t) → C(t+1)|状態が離散時間ステップで更新され、持続する                          |
|**自己と非自己の区別**|随伴の非対称性            |ShapeはCに依存しない（環境＝非自己）、ActionはCに依存する（行動＝自己）     |
|**記憶**       |エージェント状態 C         |Cの内部に記憶モジュールとして格納                              |

注目すべきは、5要件のうち4つ（差異感受性・志向性・時間的持続・自己/非自己の区別）が随伴構造から自然に導出されるという点である。記憶のみが随伴の外側に位置するが、これはエージェント状態Cの内部に格納される。記憶の内容は随伴が決め（何を記憶するか＝coherence signalが高かった経験）、記憶の保持はCが担う。

### 5.3 動的GNNによる随伴層の実装構想
随伴層の実装基盤として、以下の構造を持つ動的GNNが構想される。
静的な層として、ノードは機能プリミティブを、エッジは合成可能性を表す。随伴構造として、F（Shape→Action）はグラフ上でのメッセージパッシングとして、G（Action→Shape）はグラフ全体のリードアウト（逆方向）として実装される。変化し続ける部分として、エッジの重み（合成のしやすさ）、ノードの活性化閾値、そしてグラフのトポロジー自体（新しいプリミティブの追加）が、coherence signalに応じて更新される。

### 5.4 言語野の拡張
本モデルの構造は、言語能力の追加を同じ随伴パターンの階層化として自然に実現する。
現在の構造が Shape ⇄ Action の随伴であるのに対し、拡張後は Shape ⇄ Action ⇄ Language という2つの随伴の連鎖となる。言語は、形状と動作の随伴に「名前をつける」もう一つの随伴層である。この拡張において、新しい原理の導入は不要であり、同じ随伴＋coherenceのパターンが層ごとに繰り返されるだけである。

## 6. Active Inferenceとの対応関係と本モデルの独自性

### 6.1 構造的対応
本モデルとカール・フリストンが提唱するActive Inference（能動的推論）の間には、強い構造的対応が存在する [2]。

|本モデルの概念             |Active Inferenceの概念   |
|:-------------------|:---------------------|
|Coherence signal (η)|自由エネルギー（予測誤差）         |
|F⊣Gの動的ループ           |Action-Perception loop|
|エージェント状態 C          |生成モデルのパラメータ           |
|Coherence breakdown |サプライズ（予測外の観測）         |

特に、coherence signal ≈ 自由エネルギーという対応は本質的である。G(F(shape))は「エージェントが現在の内部状態Cと形状shapeから予測する世界のあり方」であり、distance(shape, G(F(shape)))はその予測と現実の乖離、すなわち予測誤差に他ならない。

### 6.2 本モデルの独自性
しかし、本モデルはActive Inferenceの単なる再定式化ではない。以下の概念はActive Inferenceの枠組みでは直接扱えない。
保留構造は、Active Inferenceにおける「生成モデル」とは質的に異なる。生成モデルは世界の確率的な記述であるのに対し、保留構造は「まだ決まっていない」という未確定性そのものを構造化したものである。
Coherence breakdownが創造性を生むという主張は、Active Inferenceにおけるサプライズ最小化の原理とは方向性が異なる。Active Inferenceではサプライズ（予測誤差）は最小化すべきものであるが、本モデルではcoherence breakdownは創造的問題解決の契機として積極的に位置づけられる。
随伴の非対称性——ShapeはCに依存しないがActionはCに依存する——は、Active Inferenceの対称的な枠組みでは明示的に扱われていない。

### 6.3 位置づけ
本モデルは、**「圏論という代数的な言語でActive Inferenceを再定式化し、さらに保留構造と創造性の概念で拡張したもの」**として位置づけることができる。Active Inferenceがベイズ確率論を基盤とするのに対し、本モデルは随伴関手という構造そのものに焦点を当てる。これにより、確率的な定式化が難しい概念——保留、未確定性、創造性——をより直接的に扱える可能性がある。
なお、Smithe (2024) によるStructured Active Inference [3] は、圏論的システム理論を用いてActive Inferenceを大幅に一般化した研究であり、本モデルの最も近い先行研究である。特に、「エージェントの状態によって利用可能な行動が変わる」というmode-dependenceの概念は、本モデルにおけるパラメータ付き随伴のCに直接対応する。

## 7. 実装への展望：理論を検証するためのプロトタイプ
本モデルの理論的枠組みを実証するため、以下の段階的なプロトタイプ実装と実験計画を提案する。実装の目標は、単なる機能の再現ではなく、記号接地問題の解決と創造性の創発という理論の核心を検証することにある。

### 7.1 技術要素の対応表

|理論コンポーネント       |実装方針                              |ツール・先行研究                            |
|:---------------|:---------------------------------|:-----------------------------------|
|Shape圏          |3Dオブジェクトの点群またはメッシュ                |ShapeNet [4], PartNet               |
|Action圏         |身体部位とオブジェクト表面点の関係性の確率分布           |ZSP3A [5], Contact-GraspNet [6]     |
|関手 F            |GNNによるアフォーダンス予測                   |PyTorch Geometric [7]               |
|関手 G            |GNNによる逆推論                         |条件付きデコーダ（Andries et al. 2020 [8] 参照）|
|Coherence signal|再構成誤差 distance(shape, G(F(shape)))|自己教師あり学習                            |
|エージェント状態 C      |RSSM (Recurrent State-Space Model)|DreamerV3 [9] 参照                    |
|Cの更新則           |GRU更新 → 信念推論 → 期待自由エネルギー最小化       |Çatal et al. 2020 [10] 参照           |

### 7.2 実験デザインと評価指標
理論の核心を検証するため、以下の3段階の実験設定を提案する。

**Phase 0: 基礎学習と再現性検証**
- **目的:** 既知のオブジェクトと動作のペアにおいて、随伴構造（F⊣G）が学習可能であることを示す。
- **設定:** ShapeNetの既知カテゴリ（椅子、カップ）と、それに対応する把持姿勢のペアデータで学習。
- **評価指標:** 再構成誤差の最小化、FとGの予測精度。

**Phase 1: 未知オブジェクトへの般化と記号接地問題の解決（設定A）**
- **目的:** 学習時に見たことのないオブジェクトに対し、そのアフォーダンスを創発的に推論し、適切な動作を生成できることを示す。
- **設定:** シミュレーション環境（例：PyBullet）で、シンプルな形状（立方体、円柱、その組み合わせ）と基本動作（押す、引く、持ち上げる）で学習。テスト時には、学習時に見せなかった未知の形状組み合わせ（例：立方体＋円柱の配置）を提示。
- **評価指標:** 未知形状に対するアフォーダンス推論の成功率、生成された動作の適切性。Coherence signalが安定しているか。

**Phase 2: 制約下での創造的解決とCoherence Breakdownの検証（設定B）**
- **目的:** 既存の随伴構造が破綻するような制約が与えられた際、保留構造が起動し、新しい随伴構造（動作）を創発できることを示す。
- **設定:** Phase 1の環境に、エージェントの状態Cに影響を与える制約（例：重力の変化、接触面の摩擦係数の変化、エージェントの身体の一部が使用不能になる）を追加。これによりCoherence signalが急増する状況を作り出す。
- **評価指標:** Coherence signalの増大（breakdown）と、その後の新しい動作の創発。創発された動作が制約を克服し、タスクを達成できるか。保留構造（エージェント層C）の内部状態の変化。

**Phase 3: 言語とのアラインメント（設定C）**
- **目的:** 創発されたアフォーダンスや動作に対して、エージェントが言語的な記述を生成できることを示す。これにより、記号接地問題の最終的な解決を目指す。
- **設定:** Phase 2で創発された動作に対して、「これは〇〇という動作である」という言語ラベルを生成させる。または、言語指示から新しい動作を生成させる。
- **評価指標:** 生成された言語記述の適切性、言語指示に対する動作生成の成功率。

## 8. 結論と今後の課題
本研究ノートでは、物理的意味的随伴モデルの理論的枠組みを、知性の本質としての保留構造を中心に再構築した。主要な成果を以下にまとめる。

理論的成果として、知性の本体を「未確定性を保持し、新しい意味を創発する保留構造」と定義し、その5つの要件を同定した。随伴構造は、この保留構造が「平時」に参照する安定した理解の瞬間として位置づけられ、coherence signalは保留構造を起動させるトリガーとして機能する。coherence breakdownを創造性の発生条件として形式化する枠組みを提示した。

先行研究との関係として、Active Inferenceとの強い構造的対応が確認されると同時に、保留構造・創造性・随伴の非対称性という独自の貢献が明確化された。

今後の課題として、以下が挙げられる。第一に、保留構造の「具体化される瞬間」の条件の精密な定式化。第二に、動的GNNのグラフ変形の時間スケールの設計。第三に、言語層の追加と既存のLLMとの関係の明確化。第四に、本研究ノートで提案された段階的な実験計画の実行による理論の実証。

本モデルは、「データから学習する」AIから「身体を通して世界を再定義し、新しい意味を創発する」AIへの転換を目指すものである。その射程は、AIアーキテクチャの設計に留まらず、知性そのものの再定義にまで及ぶ可能性がある。

## 参考文献
[1]: Harnad, S. (1990). The Symbol Grounding Problem. Physica D: Nonlinear Phenomena, 42(1-3), 335-346.
[2]: Parr, T., Pezzulo, G., & Friston, K. J. (2022). Active Inference: The Free Energy Principle in Mind, Brain, and Behavior. MIT Press.
[3]: Smithe, T. S. C. (2024). Structured Active Inference (Chapters 1-3). arXiv:2406.07577.
[4]: Chang, A. X., et al. (2015). ShapeNet: An Information-Rich 3D Model Repository. arXiv:1512.03012.
[5]: Kim, H., et al. (2024). Zero-Shot Learning for the Primitives of 3D Affordance in General Objects. arXiv:2401.12978.
[6]: Sundermeyer, M., et al. (2021). Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered Scenes. arXiv:2103.14243.
[7]: Fey, M., & Lenssen, J. E. (2019). Fast Graph Representation Learning with PyTorch Geometric. arXiv:1903.02428.
[8]: Andries, R., et al. (2020). Automatic Generation of Object Shapes With Desired Affordances. Frontiers in Neurorobotics, 14, 22.
[9]: Hafner, D., et al. (2023). Mastering Diverse Domains through World Models. arXiv:2301.04105.
[10]: Çatal, O., et al. (2020). Learning Generative State Space Models for Active Inference. Frontiers in Computational Neuroscience, 14, 574372.


## 補遺：保留構造と時間的持続に関する洞察

### 睡眠としてのエピソードリセット

`TEMPORAL_PERSISTENCE_PRINCIPLES.md`での分析により、時間的持続が長すぎることの危険性が明らかになった。連続的な学習は、エージェントが破壊的な戦略を発見し、それを強化してしまうリスクを伴う（η爆発）。

これは、エピソードごとにAgent Cの内部状態（意識の連続性に相当する `h, z`）をリセットすることが、人間における**睡眠**と同様の役割を果たすことを示唆している。睡眠が精神の崩壊を防ぐように、エピソードリセットはエージェントが短期的な破壊的戦略を「忘れる」ことを可能にする。一方で、長期的に有用な経験は記憶（Valence Memory）としてエピソードを超えて保持される。

この発見は、保留構造の要件である「時間的持続」に、適切な境界（エピソード長）を設ける必要性を示している。

### 休息の創発

`REST_EMERGENCE_EXPERIMENT.md`では、エージェントが明示的な休息報酬なしで、自発的に活動を抑制する「休息」を学習する可能性について論じられている。これは、価値関数の学習ダイナミクス自体が、本質的に「安定した報酬」を好む性質を持つためである。

- ηが不安定に振動すると、報酬も振動し、価値関数の推定が困難になる。
- エージェントが活動を抑制（休息）すると、ηが安定し、報酬も安定する。
- 報酬が安定すると、価値関数の学習が進み、結果として長期的な報酬が増加する。

この仮説が検証されれば、保留構造の5要件が、エージェントの自己調整能力（疲労の検知と回復）を創発させるのに十分であることを示す強力な証拠となる。
