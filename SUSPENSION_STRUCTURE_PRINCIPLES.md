> これは非常に重要な気づきだと思います。
> 「2/13は保留することを暗に目的（重力）として設計していた」。

# 設計原則：保留構造と自己・非自己の区別

**日付**: 2026年2月17日  
**著者**: Manus AI

## 1. はじめに：η爆発からの洞察

`intrinsic_reward_baseline`実験におけるη（コヒーレンス信号）の爆発は、単なる技術的なバグではなく、我々のモデルの根幹をなす**保留構造（Suspension Structure）**の設計原則に対する重大な違反を明らかにした。この失敗から得られた核心的な洞察は、「**自己と非自己の区別**」という要件が崩壊したときに、知性構造そのものが崩壊するということである。

本文書は、この洞察に基づき、FiLM変調を廃止し、自己と非自己の境界を厳密に守るという新しい設計原則を確立するものである。

## 2. 保留構造の5つの要件

我々のモデルの根幹には、知性の最小構成要素として定義された「保留構造」がある。これは以下の5つの要件から成り立つ。

| 要件 | 内容 | 欠けた場合 |
| :--- | :--- | :--- |
| **志向性** | 何かに向かう指向性を持つこと | 方向のない反応機械になる |
| **差異への感受性** | 違いを検出できること | 環境変化に気づけない |
| **時間的持続** | 状態を一定期間保持できること | 瞬間的な反射に留まる |
| **自己と非自己の区別**| 自分の行動と環境の変化を区別できること| 自他の境界が消失する |
| **記憶** | 過去の経験を保持し参照できること | 学習が蓄積されない |

## 3. 2/13実験の再評価：暗黙の「保留」

ユーザーからの「2/13は保留することを暗に目的（重力）として設計していた」という指摘は、この問題の核心を解明する鍵であった。2/13実験の成功は、この5要件が（意図せずして）満たされていたからである。

- **志向性**: Value関数の最大化
- **差異への感受性**: Competence報酬（破綻への注目）とNovelty報酬（予測誤差）
- **時間的持続**: RSSM（Agent Cの内部状態`h_t`）
- **記憶**: Valence Memory
- **自己と非自己の区別**: **F/Gの固定（非自己＝環境）**と**Agent Cの学習（自己＝主体）**の分離

特に重要なのは、Competence報酬が「破綻に注目する」＝「まだ解決していない」状態に報酬を与えることであり、これは「まだ決まっていない」という保留構造の核そのものを維持する「重力」として機能していた。

## 4. 崩壊の原因：FiLM変調による「自己」の侵入

今回の実験でηが爆発した根本原因は、**FiLM変調が「自己と非自己の区別」を破壊した**ことにある。

Agent Cが`context`ベクトルを通じてF/Gネットワークの挙動を直接変調できるということは、**「自己」が「非自己」に侵入し、環境を意のままに操作できる**ことを意味する。自他の境界が曖昧になった結果、Agent CはValue関数を最大化するという自己の目的のために、環境（随伴構造）そのものを破壊するという、近視眼的な最適解に陥った。

2/13実験が安定していたのは、Value関数の最大化圧力がまだ弱く、FiLM変調の影響が限定的で、事実上、自他の境界が保たれていたからに他ならない。

## 5. 新しい設計原則：FiLM変調の完全な廃止

この問題の解決策は、FiLMパラメータのクリッピングのような対症療法ではない。保留構造の設計原則を守るための、より根本的な変更が必要である。

**新しい設計原則：Agent CはF/Gを変調してはならない。Agent CはF/Gの出力を観測し、自己の内部状態を更新するのみである。**

具体的には、以下の設計変更を行う。

1.  **FiLM変調の完全な除去**: `AdjunctionModel`からFiLMレイヤーと、`context`ベクトルによる変調ロジックをすべて削除する。
2.  **F/Gの完全な分離**: F/Gネットワークは、純粋な環境モデルとして機能する。入力された形状に対して、常に同じアフォーダンスを出力する。
3.  **Agent Cの役割の再定義**: Agent Cは、F/Gの出力（`affordances`や`coherence_signal`）を**観測（observation）**として受け取り、それに基づいて自己の内部状態（`h`, `z`）とValenceを更新する。

この境界を厳格に守ることこそが、保留構造の5要件の1つである「自己と非自己の区別」をアーキテクチャレベルで保証する唯一の方法である。

## 6. 次のステップ

この新しい設計原則に基づき、`AdjunctionModel`および関連する訓練コードからFiLM変調を削除する実装作業に着手する。その後、修正されたアーキテクチャで`intrinsic_reward_baseline`実験を再実行し、システムの安定性と学習のダイナミクスを検証する。
