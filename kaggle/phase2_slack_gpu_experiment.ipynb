{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 Slack Experiment - GPU Accelerated\n",
    "\n",
    "This notebook runs the Phase 2 Slack experiment on Kaggle's free GPU to analyze η/ε dynamics and Agent C behavior.\n",
    "\n",
    "## Setup Instructions\n",
    "1. **Enable GPU**: Settings → Accelerator → GPU T4 x2\n",
    "2. **Run all cells** in order\n",
    "3. **Wait ~30 minutes** for 100 epochs to complete\n",
    "\n",
    "## What This Experiment Does\n",
    "- Trains F⊣G (Functors) and Agent C **simultaneously**\n",
    "- **No reconstruction loss** → preserves η (unit) as \"slack\"\n",
    "- Only minimizes affordance prediction loss\n",
    "- Observes η/ε dynamics and potential suspension structure emergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(\"=\"*60)\n",
    "print(\"GPU CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"⚠️  WARNING: GPU not available, will use CPU (much slower)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"=\"*60)\n",
    "print(\"INSTALLING DEPENDENCIES\")\n",
    "print(\"=\"*60)\n",
    "!pip install torch-geometric torch-scatter torch-sparse -q\n",
    "print(\"✓ PyTorch Geometric installed\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "print(\"=\"*60)\n",
    "print(\"CLONING REPOSITORY\")\n",
    "print(\"=\"*60)\n",
    "!git clone https://github.com/type37c/adjunction-model.git\n",
    "%cd adjunction-model\n",
    "print(\"✓ Repository cloned\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/adjunction-model')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our models and dataset\n",
    "from models.conditional_adjunction_v4 import ConditionalAdjunctionV4\n",
    "from data.synthetic_dataset import SyntheticAffordanceDataset\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'num_epochs': 100,\n",
    "    'num_shapes': 100,\n",
    "    'batch_size': 8,\n",
    "    'num_points': 512,\n",
    "    'num_affordances': 5,\n",
    "    'learning_rate': 1e-4,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'output_dir': '/kaggle/working/results/phase2_slack'\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"✓ Output directory created: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define collate function for graph batching\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function to convert batch format to graph format.\"\"\"\n",
    "    points_list = []\n",
    "    affordances_list = []\n",
    "    \n",
    "    for item in batch:\n",
    "        # item['points']: (num_points, 3)\n",
    "        # item['affordances']: (num_points, num_affordances)\n",
    "        points_list.append(item['points'])\n",
    "        affordances_list.append(item['affordances'])\n",
    "    \n",
    "    # Stack into batch format\n",
    "    points_batch = torch.stack(points_list)  # (B, N, 3)\n",
    "    affordances_batch = torch.stack(affordances_list)  # (B, N, A)\n",
    "    \n",
    "    # Convert to graph format\n",
    "    B, N, _ = points_batch.shape\n",
    "    pos = points_batch.reshape(B * N, 3)  # (B*N, 3)\n",
    "    batch_indices = torch.arange(B).repeat_interleave(N)  # (B*N,)\n",
    "    \n",
    "    return {\n",
    "        'points': pos,\n",
    "        'batch': batch_indices,\n",
    "        'affordances': affordances_batch  # Keep in batch format for loss computation\n",
    "    }\n",
    "\n",
    "print(\"✓ Collate function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset = SyntheticAffordanceDataset(\n",
    "    num_shapes=CONFIG['num_shapes'],\n",
    "    num_points=CONFIG['num_points'],\n",
    "    num_affordances=CONFIG['num_affordances']\n",
    ")\n",
    "\n",
    "# Split into train/val\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders with custom collate_fn\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"✓ Train size: {len(train_dataset)}\")\n",
    "print(f\"✓ Val size: {len(val_dataset)}\")\n",
    "print(f\"✓ Train batches: {len(train_loader)}\")\n",
    "print(f\"✓ Val batches: {len(val_loader)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = ConditionalAdjunctionV4(\n",
    "    num_affordances=CONFIG['num_affordances'],\n",
    "    f_hidden_dim=64,\n",
    "    g_hidden_dim=128,\n",
    "    agent_hidden_dim=256,\n",
    "    agent_latent_dim=64,\n",
    "    context_dim=128\n",
    ").to(CONFIG['device'])\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"✓ Model created\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "aff_criterion = nn.MSELoss()\n",
    "\n",
    "# Loss weights\n",
    "lambda_aff = 1.0\n",
    "lambda_kl = 0.1\n",
    "lambda_coherence = 0.1\n",
    "\n",
    "print(\"✓ Optimizer and loss functions created\")\n",
    "print(f\"  λ_aff: {lambda_aff}\")\n",
    "print(f\"  λ_kl: {lambda_kl}\")\n",
    "print(f\"  λ_coherence: {lambda_coherence}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_aff = 0.0\n",
    "    total_kl = 0.0\n",
    "    total_coherence = 0.0\n",
    "    total_unit = 0.0\n",
    "    total_counit = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for batch_data in pbar:\n",
    "        pos = batch_data['points'].to(device)\n",
    "        batch = batch_data['batch'].to(device)\n",
    "        affordances_gt = batch_data['affordances'].to(device)\n",
    "        \n",
    "        batch_size = batch.max().item() + 1\n",
    "        \n",
    "        # Initialize agent state\n",
    "        agent_state = model.agent_c.initial_state(batch_size, device)\n",
    "        coherence_signal_prev = torch.zeros(batch_size, 1, device=device)\n",
    "        \n",
    "        # Forward pass\n",
    "        results = model(pos, batch, agent_state, coherence_signal_prev)\n",
    "        \n",
    "        affordances_pred = results['affordances']\n",
    "        coherence_signal = results['coherence_signal']\n",
    "        counit_signal = results['counit_signal']\n",
    "        rssm_info = results['rssm_info']\n",
    "        \n",
    "        # Compute losses\n",
    "        # Convert affordances_gt to graph format\n",
    "        B_gt, N_gt, A_gt = affordances_gt.shape\n",
    "        affordances_gt_flat = affordances_gt.reshape(B_gt * N_gt, A_gt)\n",
    "        \n",
    "        L_aff = aff_criterion(affordances_pred, affordances_gt_flat)\n",
    "        \n",
    "        L_kl = model.agent_c.rssm.kl_divergence(\n",
    "            rssm_info['posterior_mean'],\n",
    "            rssm_info['posterior_std'],\n",
    "            rssm_info['prior_mean'],\n",
    "            rssm_info['prior_std']\n",
    "        ).mean()\n",
    "        \n",
    "        L_coherence = -torch.log(coherence_signal + 1e-8).mean()\n",
    "        \n",
    "        # Total loss (NO RECONSTRUCTION LOSS)\n",
    "        loss = lambda_aff * L_aff + lambda_kl * L_kl + lambda_coherence * L_coherence\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate metrics\n",
    "        total_loss += loss.item()\n",
    "        total_aff += L_aff.item()\n",
    "        total_kl += L_kl.item()\n",
    "        total_coherence += L_coherence.item()\n",
    "        total_unit += coherence_signal.mean().item()\n",
    "        total_counit += counit_signal.mean().item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'η': f'{coherence_signal.mean().item():.4f}',\n",
    "            'ε': f'{counit_signal.mean().item():.4f}'\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / num_batches,\n",
    "        'aff': total_aff / num_batches,\n",
    "        'kl': total_kl / num_batches,\n",
    "        'coherence': total_coherence / num_batches,\n",
    "        'unit_eta': total_unit / num_batches,\n",
    "        'counit_eps': total_counit / num_batches,\n",
    "    }\n",
    "\n",
    "print(\"✓ Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    total_aff = 0.0\n",
    "    total_unit = 0.0\n",
    "    total_counit = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in dataloader:\n",
    "            pos = batch_data['points'].to(device)\n",
    "            batch = batch_data['batch'].to(device)\n",
    "            affordances_gt = batch_data['affordances'].to(device)\n",
    "            \n",
    "            batch_size = batch.max().item() + 1\n",
    "            \n",
    "            agent_state = model.agent_c.initial_state(batch_size, device)\n",
    "            coherence_signal_prev = torch.zeros(batch_size, 1, device=device)\n",
    "            \n",
    "            results = model(pos, batch, agent_state, coherence_signal_prev)\n",
    "            \n",
    "            affordances_pred = results['affordances']\n",
    "            coherence_signal = results['coherence_signal']\n",
    "            counit_signal = results['counit_signal']\n",
    "            \n",
    "            B_gt, N_gt, A_gt = affordances_gt.shape\n",
    "            affordances_gt_flat = affordances_gt.reshape(B_gt * N_gt, A_gt)\n",
    "            \n",
    "            L_aff = aff_criterion(affordances_pred, affordances_gt_flat)\n",
    "            \n",
    "            total_aff += L_aff.item()\n",
    "            total_unit += coherence_signal.mean().item()\n",
    "            total_counit += counit_signal.mean().item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    return {\n",
    "        'aff': total_aff / num_batches,\n",
    "        'unit_eta': total_unit / num_batches,\n",
    "        'counit_eps': total_counit / num_batches,\n",
    "    }\n",
    "\n",
    "print(\"✓ Validation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_aff': [],\n",
    "    'train_kl': [],\n",
    "    'train_coherence': [],\n",
    "    'train_unit_eta': [],\n",
    "    'train_counit_eps': [],\n",
    "    'val_aff': [],\n",
    "    'val_unit_eta': [],\n",
    "    'val_counit_eps': [],\n",
    "}\n",
    "\n",
    "for epoch in range(1, CONFIG['num_epochs'] + 1):\n",
    "    # Train\n",
    "    train_metrics = train_epoch(model, train_loader, optimizer, CONFIG['device'], epoch)\n",
    "    \n",
    "    # Validate every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        val_metrics = validate(model, val_loader, CONFIG['device'])\n",
    "        print(f\"\\nEpoch {epoch}/{CONFIG['num_epochs']}:\")\n",
    "        print(f\"  Train - Loss: {train_metrics['loss']:.4f}, η: {train_metrics['unit_eta']:.4f}, ε: {train_metrics['counit_eps']:.4f}\")\n",
    "        print(f\"  Val   - Aff: {val_metrics['aff']:.4f}, η: {val_metrics['unit_eta']:.4f}, ε: {val_metrics['counit_eps']:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    # Save metrics\n",
    "    history['train_loss'].append(train_metrics['loss'])\n",
    "    history['train_aff'].append(train_metrics['aff'])\n",
    "    history['train_kl'].append(train_metrics['kl'])\n",
    "    history['train_coherence'].append(train_metrics['coherence'])\n",
    "    history['train_unit_eta'].append(train_metrics['unit_eta'])\n",
    "    history['train_counit_eps'].append(train_metrics['counit_eps'])\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        history['val_aff'].append(val_metrics['aff'])\n",
    "        history['val_unit_eta'].append(val_metrics['unit_eta'])\n",
    "        history['val_counit_eps'].append(val_metrics['counit_eps'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "with open(output_dir / 'metrics.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"✓ Metrics saved to {output_dir / 'metrics.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), output_dir / 'model_final.pt')\n",
    "print(f\"✓ Model saved to {output_dir / 'model_final.pt'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Phase 2 Slack Experiment - Training Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "val_epochs = range(5, CONFIG['num_epochs'] + 1, 5)\n",
    "\n",
    "# Row 1: Training metrics\n",
    "axes[0, 0].plot(epochs, history['train_aff'], color='blue', linewidth=2)\n",
    "axes[0, 0].set_title('Affordance Loss (Training)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(epochs, history['train_unit_eta'], color='green', linewidth=2, label='η (unit)')\n",
    "axes[0, 1].set_title('Unit η (Training)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('η value')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 2].plot(epochs, history['train_counit_eps'], color='red', linewidth=2, label='ε (counit)')\n",
    "axes[0, 2].set_title('Counit ε (Training)', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "axes[0, 2].set_ylabel('ε value')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Row 2: Validation metrics and summary\n",
    "if len(history['val_aff']) > 0:\n",
    "    axes[1, 0].plot(val_epochs, history['val_aff'], color='blue', linewidth=2, marker='o')\n",
    "    axes[1, 0].set_title('Affordance Loss (Validation)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Loss')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 1].plot(val_epochs, history['val_unit_eta'], color='green', linewidth=2, marker='o', label='η (unit)')\n",
    "    axes[1, 1].set_title('Unit η (Validation)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('η value')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 2].plot(val_epochs, history['val_counit_eps'], color='red', linewidth=2, marker='o', label='ε (counit)')\n",
    "    axes[1, 2].set_title('Counit ε (Validation)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 2].set_xlabel('Epoch')\n",
    "    axes[1, 2].set_ylabel('ε value')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'training_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Visualization saved to {output_dir / 'training_results.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Training (Final Epoch):\")\n",
    "print(f\"  Affordance Loss: {history['train_aff'][-1]:.6f}\")\n",
    "print(f\"  Unit η:          {history['train_unit_eta'][-1]:.6f}\")\n",
    "print(f\"  Counit ε:        {history['train_counit_eps'][-1]:.6f}\")\n",
    "print(f\"  KL Loss:         {history['train_kl'][-1]:.6f}\")\n",
    "print()\n",
    "if len(history['val_aff']) > 0:\n",
    "    print(\"Validation (Final):\")\n",
    "    print(f\"  Affordance Loss: {history['val_aff'][-1]:.6f}\")\n",
    "    print(f\"  Unit η:          {history['val_unit_eta'][-1]:.6f}\")\n",
    "    print(f\"  Counit ε:        {history['val_counit_eps'][-1]:.6f}\")\n",
    "    print()\n",
    "print(\"=\"*60)\n",
    "print(\"Key Observations:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  η preserved:     {'✓ YES' if history['train_unit_eta'][-1] > 0.01 else '✗ NO (collapsed)'}\")\n",
    "print(f\"  ε observable:    {'✓ YES' if history['train_counit_eps'][-1] > 0.01 else '✗ NO'}\")\n",
    "print(f\"  Learning:        {'✓ YES' if history['train_aff'][0] > history['train_aff'][-1] else '✗ NO'}\")\n",
    "print()\n",
    "print(f\"All results saved to: {output_dir}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all output files\n",
    "print(\"\\nOutput Files:\")\n",
    "for f in sorted(output_dir.glob('*')):\n",
    "    size = f.stat().st_size\n",
    "    print(f\"  {f.name:30s} ({size:,} bytes)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
