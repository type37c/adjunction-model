{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 Slack Experiment - GPU Accelerated\n",
    "\n",
    "This notebook runs the Phase 2 Slack experiment on Kaggle's free GPU to analyze η/ε dynamics and Agent C behavior.\n",
    "\n",
    "## Setup\n",
    "1. Enable GPU: Settings → Accelerator → GPU T4 x2\n",
    "2. Add dataset: Upload adjunction-model code as Kaggle dataset\n",
    "3. Run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch-geometric torch-scatter torch-sparse -q\n",
    "!pip install matplotlib seaborn pandas numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone or copy the adjunction-model repository\n",
    "# Option 1: Clone from GitHub\n",
    "!git clone https://github.com/type37c/adjunction-model.git\n",
    "%cd adjunction-model\n",
    "\n",
    "# Option 2: If uploaded as Kaggle dataset, copy from /kaggle/input/\n",
    "# !cp -r /kaggle/input/adjunction-model/* .\n",
    "# %cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/adjunction-model')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.models.adjunction_model import AdjunctionModel\n",
    "from src.training.train_phase2_slack import Phase2SlackTrainer\n",
    "from src.data.shapenet_dataset import ShapeNetAffordanceDataset\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'num_epochs': 100,\n",
    "    'num_shapes': 100,  # Larger dataset on GPU\n",
    "    'batch_size': 8,     # Larger batch size on GPU\n",
    "    'num_points': 512,\n",
    "    'num_affordances': 5,\n",
    "    'learning_rate': 1e-4,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'output_dir': 'results/phase2_slack_gpu'\n",
    "}\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"Shapes: {CONFIG['num_shapes']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "print(\"Creating dataset...\")\n",
    "dataset = ShapeNetAffordanceDataset(\n",
    "    num_shapes=CONFIG['num_shapes'],\n",
    "    num_points=CONFIG['num_points'],\n",
    "    num_affordances=CONFIG['num_affordances']\n",
    ")\n",
    "\n",
    "# Split into train/val\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(\"Creating model...\")\n",
    "model = AdjunctionModel(\n",
    "    num_affordances=CONFIG['num_affordances'],\n",
    "    num_points=CONFIG['num_points'],\n",
    "    f_hidden_dim=64,\n",
    "    g_hidden_dim=128,\n",
    "    agent_hidden_dim=256,\n",
    "    agent_latent_dim=64,\n",
    "    context_dim=128\n",
    ").to(CONFIG['device'])\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "print(\"Creating trainer...\")\n",
    "trainer = Phase2SlackTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    device=CONFIG['device'],\n",
    "    output_dir=str(output_dir)\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting training...\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "trainer.train(num_epochs=CONFIG['num_epochs'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training completed!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display metrics\n",
    "with open(output_dir / 'metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"\\nFinal Metrics:\")\n",
    "print(f\"  Unit η (final): {metrics['coherence_signal'][-1]:.4f}\")\n",
    "print(f\"  Affordance Loss (final): {metrics['affordance_loss'][-1]:.4f}\")\n",
    "print(f\"  KL Loss (final): {metrics['kl_loss'][-1]:.4f}\")\n",
    "print(f\"  Coherence (final): {metrics['coherence'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display visualizations\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"\\nSlack Signals:\")\n",
    "display(Image(filename=str(output_dir / 'slack_signals.png')))\n",
    "\n",
    "print(\"\\nTraining Losses:\")\n",
    "display(Image(filename=str(output_dir / 'training_losses.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for download\n",
    "print(\"\\nResults saved to:\", output_dir)\n",
    "print(\"\\nFiles:\")\n",
    "for f in sorted(output_dir.glob('*')):\n",
    "    print(f\"  - {f.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
